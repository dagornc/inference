# =============================================================================
# ÉTAPE 03 : RERANKING MULTI-ÉTAGES (RAG ULTIME 2025)
# =============================================================================
# Pipeline de reranking en plusieurs passes pour optimiser le trade-off
# qualité/latence/coût.
#
# ARCHITECTURE (3 passes) :
# 1. Préréranking : 100 → 50 docs (filtre rapide, <50ms)
# 2. Reranking SOTA : 50 → 20 docs (cross-encoder, 200-500ms)
# 3. Post-reranking : 20 → 10-15 docs (filtres qualité, <50ms)
#
# VALEUR AJOUTÉE :
# - Pousse les chunks les plus pertinents en tête
# - Fusionne résultats de multiples sources
# - Scores de relevance pour observabilité
# - Amélioration nDCG@10 : >0.85 pour cross-encoders SOTA
#
# OBJECTIF :
# Partir de 100 candidats (retrieval) pour arriver à 10-15 documents
# ultra-pertinents qui seront envoyés au LLM de génération.
# =============================================================================

reranking:
  # Activer/désactiver le reranking complet
  enabled: true

  # ============================================================================
  # 3.1 PRÉRÉRANKING (Fast First Pass)
  # ============================================================================
  # Filtrage rapide pour réduire la charge du reranker principal.
  # Utilise un modèle léger pour éliminer rapidement les documents peu pertinents.
  #
  # OUTILS :
  # - RAGatouille : reranking rapide via ColBERT
  # - MiniLM : modèle léger et rapide
  # - BGE-small : alternative compacte
  #
  # PERFORMANCE :
  # - Input → Output : 100 → 50 documents
  # - Latence : <50ms
  # - Objectif : éliminer 50% des moins pertinents rapidement
  # ============================================================================
  prereranking:
    enabled: true

    # Outil/modèle de préréranking
    # Options : "ragatouille", "minilm", "bge-small"
    tool: "ragatouille"

    # Modèle spécifique (si applicable)
    model: "colbert-ir/colbertv2.0"

    # Nombre de documents en entrée (depuis fusion)
    input_top_k: 100

    # Nombre de documents en sortie (vers reranking SOTA)
    output_top_k: 50

    # Latence cible (ms)
    latency_target_ms: 50

    # Méthode de scoring
    # Options : "colbert_maxsim", "cosine_similarity", "dot_product"
    scoring_method: "colbert_maxsim"

  # ============================================================================
  # 3.2 RERANKING SOTA (Cross-Encoder)
  # ============================================================================
  # Reranking de haute qualité avec un cross-encoder.
  # Le modèle traite query + document ensemble pour une évaluation fine.
  #
  # MODÈLES RECOMMANDÉS 2025 :
  # - bge-reranker-v2-m3 : open-source, multilingue, performant
  # - Cohere Rerank : API payante, excellent (nécessite COHERE_API_KEY)
  # - MixedBread mxbai-rerank-large : open-source, SOTA
  #
  # ARCHITECTURE :
  # Cross-encoder = query et document traités ensemble dans le modèle
  # → Compréhension fine des relations sémantiques
  # → Plus précis mais plus lent que bi-encoder
  #
  # PERFORMANCE :
  # - Input → Output : 50 → 20 documents
  # - Latence : 200-500ms (selon modèle et hardware)
  # - nDCG@10 : >0.85 pour modèles SOTA
  # ============================================================================
  reranking_sota:
    enabled: true

    # Provider du reranker
    # Options : "sentence_transformers", "cohere", "huggingface"
    provider: "sentence_transformers"

    # Modèle de reranking (cross-encoder)
    # RECOMMANDÉ : "BAAI/bge-reranker-v2-m3" (gratuit, multilingue, performant)
    model: "BAAI/bge-reranker-v2-m3"

    # Nombre de documents en entrée (depuis préréranking)
    input_top_k: 50

    # Nombre de documents en sortie (vers post-reranking)
    output_top_k: 20

    # Latence cible (ms)
    # Cross-encoder est plus lent, budget réaliste : 200-500ms
    latency_target_ms: 300

    # Batch size pour l'inférence
    # Augmenter si GPU disponible pour parallélisation
    batch_size: 8

    # Normalisation des scores de relevance (0-1)
    normalize_scores: true

    # Seuil de score minimum pour conserver un document
    # Documents avec score < threshold sont éliminés
    # Valeur typique : 0.3-0.5 (à ajuster selon le modèle)
    min_score_threshold: 0.4

  # --- EXEMPLE CONFIGURATION ALTERNATIVE (Cohere) ---
  # reranking_sota:
  #   enabled: true
  #   provider: "cohere"
  #   model: "rerank-english-v2.0"  # ou "rerank-multilingual-v2.0"
  #   api_key: "${COHERE_API_KEY}"  # Variable d'environnement
  #   input_top_k: 50
  #   output_top_k: 20
  #   latency_target_ms: 200

  # ============================================================================
  # 3.3 POST-RERANKING (Final Filtering & Diversification)
  # ============================================================================
  # Filtrage et optimisation finale avant envoi au LLM de génération.
  #
  # OBJECTIFS :
  # - Filtrer par score de relevance (>0.6-0.7)
  # - Assurer diversité des sources
  # - Éliminer doublons résiduels
  # - Limiter à 10-15 chunks maximum (context window optimization)
  #
  # OUTILS :
  # - Rankify : métriques QA et passage optimisé vers LLM
  # - MMR : Maximal Marginal Relevance pour diversification
  #
  # PERFORMANCE :
  # - Input → Output : 20 → 10-15 documents
  # - Latence : 20-50ms
  # - Métriques : precision, recall, nDCG pour évaluation continue
  # ============================================================================
  postreranking:
    enabled: true

    # Nombre de documents en entrée (depuis reranking SOTA)
    input_top_k: 20

    # Nombre de documents final (vers génération)
    # Recommandé : 10-15 pour équilibre contexte/performance
    output_top_k: 15

    # Latence cible (ms)
    latency_target_ms: 50

    # ---------------------------------------------------------------------------
    # FILTRAGE PAR SCORE DE RELEVANCE
    # ---------------------------------------------------------------------------
    # Éliminer les documents avec score de relevance trop faible
    score_filtering:
      enabled: true
      # Seuil minimum (0-1)
      # Documents avec score < threshold sont exclus
      # Valeur typique : 0.6-0.7 (plus strict que reranking SOTA)
      min_score: 0.6

    # ---------------------------------------------------------------------------
    # DIVERSIFICATION DES SOURCES
    # ---------------------------------------------------------------------------
    # Assurer variété des sources pour réponse complète
    diversification:
      enabled: true

      # Méthode de diversification
      # Options : "mmr" (Maximal Marginal Relevance), "source_coverage", "both"
      method: "mmr"

      # Lambda pour MMR (0-1)
      # 0 = diversité maximale, 1 = relevance maximale
      # Recommandé : 0.5-0.7 pour équilibre
      mmr_lambda: 0.6

      # Nombre maximum de chunks de la même source
      # Évite surreprésentation d'un document
      max_chunks_per_source: 3

    # ---------------------------------------------------------------------------
    # DÉDUPLICATION FINALE
    # ---------------------------------------------------------------------------
    # Éliminer doublons résiduels après tous les traitements
    deduplication:
      enabled: true
      # Seuil de similarité (0-1)
      # Plus strict que la déduplication du retrieval
      similarity_threshold: 0.90
      method: "cosine"

    # ---------------------------------------------------------------------------
    # MÉTRIQUES DE QUALITÉ
    # ---------------------------------------------------------------------------
    # Calculer et logger des métriques pour monitoring continu
    metrics:
      enabled: true
      # Métriques à calculer : "precision", "recall", "ndcg", "mrr"
      compute: ["precision", "recall", "ndcg@10", "mrr"]
      # Logger les métriques pour observabilité
      log_metrics: true

# =============================================================================
# EXEMPLE D'UTILISATION
# =============================================================================
# Le pipeline de reranking complet :
#
# 1. Préréranking (RAGatouille/ColBERT)
#    Entrée : 100 candidats du retrieval hybride
#    Sortie : 50 documents pré-filtrés
#    Latence : ~30ms
#
# 2. Reranking SOTA (bge-reranker-v2-m3)
#    Entrée : 50 documents pré-filtrés
#    Sortie : 20 documents reordonnés avec scores
#    Latence : ~250ms
#
# 3. Post-reranking (Filtres + MMR)
#    Entrée : 20 documents scorés
#    Sortie : 15 documents finaux, diversifiés, haute qualité
#    Latence : ~30ms
#
# TOTAL : 100 → 15 documents en ~310ms
# =============================================================================
