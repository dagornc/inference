# =============================================================================
# √âTAPE 03 v2 : RERANKING AVANC√â - ARCHITECTURE 10 SOUS-√âTAPES (RAG ULTIME 2025+)
# =============================================================================
# Pipeline reranking enrichi avec feature engineering, contextualization,
# LLM reranking, hybrid fusion, et validation qualit√©.
#
# ARCHITECTURE v2 (10 SOUS-√âTAPES) :
# 3.1  ‚Üí Query-Document Feature Engineering
# 3.2  ‚Üí Contextualization
# 3.3  ‚Üí Pr√©r√©ranking
# 3.4  ‚Üí Cross-Encoder Reranking
# 3.5  ‚Üí LLM Reranking
# 3.6  ‚Üí Hybrid Reranking Fusion
# 3.7  ‚Üí Score Calibration
# 3.8  ‚Üí Adaptive Filtering
# 3.9  ‚Üí Diversification & Deduplication
# 3.10 ‚Üí Quality Validation & Metrics
#
# GAINS ATTENDUS :
# - Qualit√© : +30-50% nDCG@10 vs v1
# - Latence : +50ms (sans LLM) ou +4-6s (avec LLM)
# - Robustesse : calibration, validation, monitoring
#
# COMPATIBILIT√â :
# - Backward compatible avec v1 (d√©sactiver √©tapes 3.1, 3.2, 3.5-3.8, 3.10)
# =============================================================================

reranking:
  enabled: true

# =============================================================================
# 3.1 QUERY-DOCUMENT FEATURE ENGINEERING ‚ú® NEW
# =============================================================================
# Extraction de features explicites pour hybrid reranking et explainability.
#
# OBJECTIFS :
# - Extraire LEXICAL features (term overlap, BM25, TF-IDF)
# - Extraire SEMANTIC features (embedding similarity)
# - Extraire STRUCTURAL features (doc length, position)
# - Extraire METADATA features (domain match, temporal match)
#
# UTILIT√â :
# - Input pour hybrid fusion (3.6)
# - Explainability (pourquoi doc rank√© position X)
# - Debugging (identifier probl√®mes)
#
# GAINS :
# - +3-5% pr√©cision (si utilis√© pour hybrid fusion)
# - Interpr√©tabilit√©
#
# LATENCE : +15ms
# =============================================================================
feature_engineering:
  enabled: true

  # ---------------------------------------------------------------------------
  # LEXICAL FEATURES
  # ---------------------------------------------------------------------------
  lexical_features:
    enabled: true

    # Term overlap (Jaccard similarity)
    term_overlap:
      enabled: true
      method: "jaccard"  # ou "dice", "cosine"
      normalize: true    # Normaliser par length

    # BM25 score
    bm25_score:
      enabled: true
      params:
        k1: 1.5
        b: 0.75

    # TF-IDF similarity
    tfidf_similarity:
      enabled: true

    # Edit distance (Levenshtein)
    edit_distance:
      enabled: false  # D√©sactiv√© (lent)

  # ---------------------------------------------------------------------------
  # SEMANTIC FEATURES
  # ---------------------------------------------------------------------------
  semantic_features:
    enabled: true

    # Embedding similarity (dense)
    embedding_similarity:
      enabled: true
      model: "BAAI/bge-m3"
      method: "cosine"

    # Cross-attention score (si cross-encoder d√©j√† calcul√©)
    cross_attention_score:
      enabled: false  # Calcul√© automatiquement par cross-encoder

  # ---------------------------------------------------------------------------
  # STRUCTURAL FEATURES
  # ---------------------------------------------------------------------------
  structural_features:
    enabled: true

    # Document length (tokens)
    doc_length:
      enabled: true
      normalize: true  # Normaliser 0-1

    # Original rank (position dans retrieval)
    original_rank:
      enabled: true
      normalize: true

    # Position in list
    position:
      enabled: true

  # ---------------------------------------------------------------------------
  # METADATA FEATURES
  # ---------------------------------------------------------------------------
  metadata_features:
    enabled: true

    # Domain match (query domain == doc domain)
    domain_match:
      enabled: true
      boost_factor: 1.1  # Si match, boost +10%

    # Temporal match (query date == doc date)
    temporal_match:
      enabled: true
      boost_factor: 1.15  # Si match, boost +15%
      tolerance_days: 365  # Tol√©rance ¬±1 an

    # Language match
    language_match:
      enabled: true
      boost_factor: 1.05

    # Geographic match
    geographic_match:
      enabled: false  # Optionnel

  # ---------------------------------------------------------------------------
  # FEATURE STORAGE
  # ---------------------------------------------------------------------------
  # Stocker features pour chaque doc (utilis√© par 3.6, 3.10)
  store_features: true

# =============================================================================
# 3.2 CONTEXTUALIZATION ‚ú® NEW
# =============================================================================
# Ajout de contexte (metadata) au texte avant reranking.
#
# OBJECTIFS :
# - DOCUMENT contextualization : [Metadata] + Texte
# - QUERY contextualization : ajouter query type/intent
# - HYBRID contextualization : contexte query + doc
#
# GAINS :
# - +4-6% pr√©cision (meilleure compr√©hension contexte)
# - +8% recall sur queries metadata-rich
#
# LATENCE : +10ms
# =============================================================================
contextualization:
  enabled: true

  # ---------------------------------------------------------------------------
  # DOCUMENT CONTEXTUALIZATION
  # ---------------------------------------------------------------------------
  document_context:
    enabled: true

    # Champs metadata √† ajouter
    metadata_fields:
      - "title"
      - "author"
      - "date"
      - "domain"
      - "source"

    # Template
    # {metadata} sera remplac√© par les m√©tadonn√©es
    # {text} sera remplac√© par le texte du document
    template: "[{metadata}] {text}"

    # Truncation si trop long
    max_length: 512
    truncation: "end"  # ou "start", "middle"

  # ---------------------------------------------------------------------------
  # QUERY CONTEXTUALIZATION
  # ---------------------------------------------------------------------------
  query_context:
    enabled: true

    # Ajouter query type (de Phase 01)
    add_query_type: true
    # Exemple : [Factual] Qui a cr√©√© Python ?

    # Ajouter query intent (de Phase 01)
    add_query_intent: true
    # Exemple : [Search] Qui a cr√©√© Python ?

    # Ajouter complexity score
    add_complexity: false  # Optionnel

    # Template
    template: "[{type}|{intent}] {query}"

  # ---------------------------------------------------------------------------
  # HYBRID CONTEXTUALIZATION
  # ---------------------------------------------------------------------------
  hybrid_context:
    enabled: false  # D√©sactiv√© par d√©faut (redondant)

    # Combine query context + doc context
    template: "{query_context} ‚Üí {doc_context}"

# =============================================================================
# 3.3 PR√âR√âRANKING (Enhanced)
# =============================================================================
# Filtrage rapide 100‚Üí50 docs.
#
# AM√âLIORATIONS v2 :
# - Multiple methods (ColBERT + MiniLM + BGE-small)
# - Ensemble prereranking (fusion scores)
# - Adaptive top-k (selon complexity)
#
# GAINS :
# - +5% avec ensemble vs single
#
# LATENCE : 50ms (inchang√©)
# =============================================================================
prereranking:
  enabled: true

  # ---------------------------------------------------------------------------
  # SINGLE METHOD (v1 mode)
  # ---------------------------------------------------------------------------
  single_method:
    enabled: true  # Si false, utilise ensemble

    # Outil/mod√®le
    # Options : "ragatouille", "minilm", "bge-small"
    tool: "ragatouille"
    model: "colbert-ir/colbertv2.0"

    # Top-k
    input_top_k: 100
    output_top_k: 50

    # Scoring method
    scoring_method: "colbert_maxsim"

    # Latence cible
    latency_target_ms: 50

  # ---------------------------------------------------------------------------
  # ENSEMBLE METHOD ‚ú® NEW
  # ---------------------------------------------------------------------------
  ensemble_method:
    enabled: false  # D√©sactiv√© par d√©faut (plus lent)

    # M√©thodes combin√©es
    methods:
      - name: "colbert"
        tool: "ragatouille"
        model: "colbert-ir/colbertv2.0"
        weight: 0.6

      - name: "minilm"
        tool: "sentence_transformers"
        model: "sentence-transformers/all-MiniLM-L6-v2"
        weight: 0.4

    # Fusion
    fusion_method: "weighted_sum"  # ou "RRF"

  # ---------------------------------------------------------------------------
  # ADAPTIVE TOP-K ‚ú® NEW
  # ---------------------------------------------------------------------------
  adaptive_top_k:
    enabled: true

    # Mapping complexity ‚Üí top_k
    by_complexity:
      simple: 30      # complexity < 0.3
      medium: 50      # complexity 0.3-0.6
      complex: 70     # complexity > 0.6

# =============================================================================
# 3.4 CROSS-ENCODER RERANKING (Enhanced)
# =============================================================================
# Reranking SOTA avec cross-encoder.
#
# AM√âLIORATIONS v2 :
# - Contextualized input (utilise 3.2)
# - Batch optimization (batching intelligent)
# - Score normalization (robuste)
#
# GAINS :
# - +3% avec contextualization
#
# LATENCE : 300ms (inchang√©)
# =============================================================================
cross_encoder:
  enabled: true

  # ---------------------------------------------------------------------------
  # PROVIDER & MODEL
  # ---------------------------------------------------------------------------
  provider: "sentence_transformers"
  model: "BAAI/bge-reranker-v2-m3"

  # ---------------------------------------------------------------------------
  # TOP-K
  # ---------------------------------------------------------------------------
  input_top_k: 50
  output_top_k: 20

  # ---------------------------------------------------------------------------
  # CONTEXTUALIZED INPUT ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Utilise contextualization de 3.2
  contextualized_input: true

  # ---------------------------------------------------------------------------
  # BATCH OPTIMIZATION
  # ---------------------------------------------------------------------------
  batch_size: 8

  # Adaptive batching (ajuster batch_size selon GPU mem)
  adaptive_batching:
    enabled: true
    min_batch_size: 4
    max_batch_size: 16

  # ---------------------------------------------------------------------------
  # SCORE NORMALIZATION
  # ---------------------------------------------------------------------------
  normalize_scores: true

  # M√©thode de normalisation
  # Options : "minmax", "softmax", "zscore"
  normalization_method: "minmax"

  # ---------------------------------------------------------------------------
  # FILTERING
  # ---------------------------------------------------------------------------
  # Seuil minimum pour conserver doc
  min_score_threshold: 0.4

  # ---------------------------------------------------------------------------
  # ADVANCED
  # ---------------------------------------------------------------------------
  latency_target_ms: 300

  # Cohere alternative configuration (si provider=cohere)
  # cohere:
  #   api_key: "${COHERE_API_KEY}"
  #   model: "rerank-multilingual-v2.0"

# =============================================================================
# 3.5 LLM RERANKING ‚ú® NEW
# =============================================================================
# Reranking haute qualit√© avec LLM (RankGPT/RankLLM).
#
# M√âTHODES :
# - Pointwise : score chaque doc (O(N))
# - Pairwise : compare paires (O(N¬≤))
# - Listwise : reorder liste (optimal, long prompt)
#
# GAINS :
# - +5-8% pr√©cision
# - +10-15% nDCG@10
#
# LATENCE : +4-6 secondes (TR√àS lent)
#
# RECOMMANDATION :
# - Activer UNIQUEMENT si qualit√© primordiale
# - Utiliser sur top-10 seulement
# - Consid√©rer activation conditionnelle (queries complexes uniquement)
# =============================================================================
llm_reranking:
  enabled: false  # D√©sactiv√© par d√©faut (trop lent)

  # ---------------------------------------------------------------------------
  # LLM PROVIDER
  # ---------------------------------------------------------------------------
  provider: "ollama"
  model: "llama3"

  # ---------------------------------------------------------------------------
  # RERANKING METHOD
  # ---------------------------------------------------------------------------
  # Options : "pointwise", "pairwise", "listwise"
  method: "listwise"

  # Pointwise : score chaque doc ind√©pendamment (O(N))
  # Pairwise : compare docs 2 √† 2 (O(N¬≤))
  # Listwise : reorder liste compl√®te (optimal, long prompt)

  # ---------------------------------------------------------------------------
  # TOP-K
  # ---------------------------------------------------------------------------
  # IMPORTANT : utiliser UNIQUEMENT sur top-10 pour latence
  input_top_k: 10
  output_top_k: 10

  # ---------------------------------------------------------------------------
  # LLM PARAMETERS
  # ---------------------------------------------------------------------------
  temperature: 0.0
  max_tokens: 2000

  # ---------------------------------------------------------------------------
  # PROMPT TEMPLATE
  # ---------------------------------------------------------------------------
  prompt_template:
    listwise: |
      You are an expert relevance evaluator. Rank the following documents by relevance to the query.
      Return the reordered document IDs as a comma-separated list.

      Query: {query}

      Documents:
      {documents}

      Reordered IDs:

    pointwise: |
      Rate the relevance of the following document to the query on a scale of 0-10.

      Query: {query}
      Document: {document}

      Relevance score (0-10):

    pairwise: |
      Which document is more relevant to the query? Respond with "A" or "B".

      Query: {query}
      Document A: {doc_a}
      Document B: {doc_b}

      More relevant:

  # ---------------------------------------------------------------------------
  # CONDITIONAL ACTIVATION ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Activer LLM reranking UNIQUEMENT si conditions remplies
  conditional_activation:
    enabled: true

    # Conditions
    conditions:
      # Activer si query complexity > threshold
      min_complexity: 0.7

      # Activer si query type dans liste
      query_types: ["analytical", "comparative"]

      # Activer si top-1 cross-encoder score < threshold
      max_top1_score: 0.8  # Si score bas, utiliser LLM

  # ---------------------------------------------------------------------------
  # ADVANCED
  # ---------------------------------------------------------------------------
  # Cache LLM responses (queries r√©p√©t√©es)
  cache_enabled: true
  cache_ttl: 3600

  # Latence cible (pour logging/monitoring)
  latency_target_ms: 4000

# =============================================================================
# 3.6 HYBRID RERANKING FUSION ‚ú® NEW
# =============================================================================
# Fusion scores de multiples rerankers.
#
# RERANKERS COMBIN√âS :
# - BGE-reranker-v2-m3 (weight: 0.5)
# - Cohere Rerank (weight: 0.3)
# - jina-reranker-v2 (weight: 0.2)
#
# GAINS :
# - +6-10% pr√©cision vs single reranker
# - +8% nDCG@10
# - Robustesse (consensus)
#
# LATENCE : +100ms (parallel API calls)
#
# RECOMMANDATION :
# - Activer si budget latence OK
# - Utiliser 2-3 rerankers (pas plus)
# =============================================================================
hybrid_fusion:
  enabled: false  # D√©sactiv√© par d√©faut (multiple API calls co√ªteux)

  # ---------------------------------------------------------------------------
  # RERANKERS
  # ---------------------------------------------------------------------------
  rerankers:
    # Reranker 1 : BGE (local, gratuit)
    - name: "bge"
      provider: "sentence_transformers"
      model: "BAAI/bge-reranker-v2-m3"
      weight: 0.5
      enabled: true

    # Reranker 2 : Cohere (API, payant)
    - name: "cohere"
      provider: "cohere"
      model: "rerank-multilingual-v2.0"
      api_key: "${COHERE_API_KEY}"
      weight: 0.3
      enabled: false  # D√©sactiv√© par d√©faut (co√ªt)

    # Reranker 3 : jina (API, gratuit tier)
    - name: "jina"
      provider: "jina"
      model: "jina-reranker-v2-base-multilingual"
      api_key: "${JINA_API_KEY}"
      weight: 0.2
      enabled: false  # D√©sactiv√© par d√©faut

  # ---------------------------------------------------------------------------
  # FUSION METHOD
  # ---------------------------------------------------------------------------
  # Options : "weighted_sum", "RRF", "learned"
  fusion_method: "weighted_sum"

  # RRF parameters (si fusion_method=RRF)
  rrf:
    k: 60

  # Learned fusion (si fusion_method=learned)
  learned:
    model: "xgboost"
    model_path: "models/fusion_model.pkl"
    features:  # Utilise features de 3.1
      - "cross_encoder_score"
      - "embedding_similarity"
      - "bm25_score"
      - "metadata_match"

  # ---------------------------------------------------------------------------
  # ADVANCED
  # ---------------------------------------------------------------------------
  # Fallback si 1 reranker fail
  fallback_on_error: true

  # Parallel execution (reduce latency)
  parallel_execution: true

# =============================================================================
# 3.7 SCORE CALIBRATION ‚ú® NEW
# =============================================================================
# Calibration scores reranking pour interpr√©tation probabiliste.
#
# M√âTHODES :
# - Platt scaling : logistic regression
# - Isotonic regression : non-parametric
# - Temperature scaling : simple, efficace
#
# GAINS :
# - +5% precision (meilleur filtering avec seuils calibr√©s)
# - Confiance fiable (score 0.9 = vraiment 90% relevance)
#
# LATENCE : +5ms
# =============================================================================
score_calibration:
  enabled: true

  # ---------------------------------------------------------------------------
  # CALIBRATION METHOD
  # ---------------------------------------------------------------------------
  # Options : "temperature_scaling", "platt", "isotonic"
  method: "temperature_scaling"

  # ---------------------------------------------------------------------------
  # TEMPERATURE SCALING
  # ---------------------------------------------------------------------------
  temperature_scaling:
    # Temperature parameter (>1 = moins confident, <1 = plus confident)
    temperature: 1.5

    # Apprendre temperature sur dataset valid√©
    learn_temperature: false
    calibration_dataset: "data/calibration_labels.json"

  # ---------------------------------------------------------------------------
  # PLATT SCALING
  # ---------------------------------------------------------------------------
  platt_scaling:
    # Logistic regression A*score + B
    # Param√®tres appris sur dataset valid√©
    model_path: "models/platt_calibration.pkl"

  # ---------------------------------------------------------------------------
  # ISOTONIC REGRESSION
  # ---------------------------------------------------------------------------
  isotonic_regression:
    # Non-parametric calibration
    model_path: "models/isotonic_calibration.pkl"

  # ---------------------------------------------------------------------------
  # APPLICATION
  # ---------------------------------------------------------------------------
  # Appliquer calibration √† tous scores
  apply_to_all_scores: true

# =============================================================================
# 3.8 ADAPTIVE FILTERING ‚ú® NEW
# =============================================================================
# Filtrage adaptatif selon query complexity/type.
#
# TECHNIQUES :
# - Query-adaptive thresholds (seuils selon query)
# - Dynamic top-k (nombre docs final adaptatif)
# - Confidence-based filtering (filtrer si confidence faible)
#
# GAINS :
# - +3% precision (meilleur filtering)
# - -10% latence sur queries simples
#
# LATENCE : +5ms
# =============================================================================
adaptive_filtering:
  enabled: true

  # ---------------------------------------------------------------------------
  # ADAPTIVE THRESHOLDS
  # ---------------------------------------------------------------------------
  adaptive_thresholds:
    enabled: true

    # Thresholds par complexity
    by_complexity:
      simple: 0.5      # complexity < 0.3
      medium: 0.6      # complexity 0.3-0.6
      complex: 0.7     # complexity > 0.6

    # Thresholds par query type
    by_query_type:
      factual: 0.65
      analytical: 0.6
      conversational: 0.55
      navigational: 0.7
      comparative: 0.6

    # Default threshold (si aucun match)
    default: 0.6

  # ---------------------------------------------------------------------------
  # ADAPTIVE TOP-K
  # ---------------------------------------------------------------------------
  adaptive_top_k:
    enabled: true

    # Top-k par complexity
    by_complexity:
      simple: 5       # complexity < 0.3
      medium: 10      # complexity 0.3-0.6
      complex: 15     # complexity > 0.6

    # Top-k par query type
    by_query_type:
      factual: 8
      analytical: 12
      conversational: 6
      navigational: 5
      comparative: 15

    # Default top-k
    default: 10

  # ---------------------------------------------------------------------------
  # CONFIDENCE-BASED FILTERING
  # ---------------------------------------------------------------------------
  confidence_filtering:
    enabled: true

    # Confidence minimum requise
    min_confidence: 0.7

    # Action si confidence < min
    # Options : "filter" (√©liminer), "flag" (marquer), "warn" (logger)
    action: "flag"

# =============================================================================
# 3.9 DIVERSIFICATION & DEDUPLICATION (Enhanced)
# =============================================================================
# Diversifier sources et √©liminer doublons.
#
# AM√âLIORATIONS v2 :
# - MMR with features (utilise features de 3.1)
# - Source coverage (assurer multi-sources)
# - Temporal diversity (varier p√©riodes)
# - Near-duplicate detection (doublons subtils)
#
# GAINS :
# - +5% diversity
# - +3% precision (√©limination doublons)
#
# LATENCE : 30ms (inchang√©)
# =============================================================================
diversification:
  enabled: true

  # ---------------------------------------------------------------------------
  # MMR (Maximal Marginal Relevance)
  # ---------------------------------------------------------------------------
  mmr:
    enabled: true

    # Lambda (0-1)
    # 0 = diversit√© maximale, 1 = relevance maximale
    lambda: 0.6

    # Use features ‚ú® NEW
    # Utilise features de 3.1 pour calcul diversit√©
    use_features: true

  # ---------------------------------------------------------------------------
  # SOURCE COVERAGE ‚ú® NEW
  # ---------------------------------------------------------------------------
  source_coverage:
    enabled: true

    # Max chunks par source (√©viter surrepr√©sentation)
    max_chunks_per_source: 3

    # Min sources uniques requises
    min_unique_sources: 3

  # ---------------------------------------------------------------------------
  # TEMPORAL DIVERSITY ‚ú® NEW
  # ---------------------------------------------------------------------------
  temporal_diversity:
    enabled: true

    # Spread temporal minimum (jours)
    min_temporal_spread: 365  # Au moins 1 an d'√©cart

    # Boost docs de p√©riodes diff√©rentes
    boost_different_periods: true

# ---------------------------------------------------------------------------
# DEDUPLICATION
# ---------------------------------------------------------------------------
deduplication:
  enabled: true

  # Seuil de similarit√© (0-1)
  # Plus strict que retrieval (0.90 vs 0.95)
  similarity_threshold: 0.90

  # M√©thode
  # Options : "cosine", "jaccard", "edit_distance"
  method: "cosine"

  # Near-duplicate detection ‚ú® NEW
  # D√©tecte documents tr√®s similaires mais pas identiques
  near_duplicate_detection:
    enabled: true
    threshold: 0.85  # Plus permissif

  # Strat√©gie de conservation
  # Options : "first", "best_score", "most_recent"
  keep_strategy: "best_score"

# =============================================================================
# 3.10 QUALITY VALIDATION & METRICS ‚ú® NEW
# =============================================================================
# Validation qualit√© r√©sultats et monitoring.
#
# VALIDATIONS :
# - Coverage check (r√©sultats couvrent query aspects)
# - Confidence check (scores suffisamment √©lev√©s)
# - Diversity check (vari√©t√© sources)
#
# M√âTRIQUES :
# - nDCG@5, nDCG@10 (ranking quality)
# - Precision@5, Recall@10 (relevance)
# - MRR (Mean Reciprocal Rank)
#
# VALEUR :
# - Monitoring, debugging, optimisation
#
# LATENCE : +10ms
# =============================================================================
quality_validation:
  enabled: true

  # ---------------------------------------------------------------------------
  # COVERAGE CHECK
  # ---------------------------------------------------------------------------
  coverage_check:
    enabled: true

    # Coverage minimale requise (0-1)
    min_coverage: 0.7

    # Query aspects √† couvrir
    # Bas√© sur Phase 01 : entities, keywords, topics
    query_aspects:
      - "entities"
      - "keywords"
      - "topics"

    # Action si coverage < min
    # Options : "warn", "trigger_fallback", "continue"
    action: "warn"

  # ---------------------------------------------------------------------------
  # CONFIDENCE CHECK
  # ---------------------------------------------------------------------------
  confidence_check:
    enabled: true

    # Confidence moyenne minimale
    min_avg_confidence: 0.7

    # Action si confidence < min
    action: "warn"

  # ---------------------------------------------------------------------------
  # DIVERSITY CHECK
  # ---------------------------------------------------------------------------
  diversity_check:
    enabled: true

    # Min sources uniques
    min_unique_sources: 3

    # Action si diversity insuffisante
    action: "warn"

# ---------------------------------------------------------------------------
# METRICS
# ---------------------------------------------------------------------------
metrics:
  enabled: true

  # ---------------------------------------------------------------------------
  # M√âTRIQUES √Ä CALCULER
  # ---------------------------------------------------------------------------
  compute_metrics:
    # Ranking quality
    - "ndcg@5"
    - "ndcg@10"

    # Relevance
    - "precision@5"
    - "recall@10"

    # Position
    - "mrr"  # Mean Reciprocal Rank

  # ---------------------------------------------------------------------------
  # FREQUENCY
  # ---------------------------------------------------------------------------
  # Options : "per_query", "batch", "hourly"
  compute_frequency: "per_query"

  # ---------------------------------------------------------------------------
  # LABELS
  # ---------------------------------------------------------------------------
  # N√©cessite relevance judgments pour calcul
  requires_labels: true
  labels_path: "data/relevance_labels.json"

  # ---------------------------------------------------------------------------
  # LOGGING
  # ---------------------------------------------------------------------------
  log_metrics: true

  # ---------------------------------------------------------------------------
  # EXPORT
  # ---------------------------------------------------------------------------
  export:
    enabled: true
    format: "prometheus"

    prometheus:
      endpoint: "http://prometheus:9090"
      push_interval: "30s"

    # JSON export (alternative)
    json:
      enabled: false
      output_path: "logs/reranking_metrics.json"

# =============================================================================
# üèÅ CONFIGURATION GLOBALE
# =============================================================================

# Latence cible totale (ms)
global_latency_target_ms: 400  # Sans LLM
# global_latency_target_ms: 4500  # Avec LLM

# Mode debug
debug:
  enabled: false
  verbose: false

  # Log chaque sous-√©tape
  log_substeps: true

  # Alertes latence
  latency_alerts:
    step_3_1: 20    # Feature engineering
    step_3_2: 15    # Contextualization
    step_3_3: 60    # Prereranking
    step_3_4: 350   # Cross-encoder
    step_3_5: 5000  # LLM reranking (tr√®s lent)
    step_3_6: 150   # Hybrid fusion
    step_3_7: 10    # Calibration
    step_3_8: 10    # Adaptive filtering
    step_3_9: 40    # Diversification
    step_3_10: 15   # Validation

# =============================================================================
# üìù NOTES D'UTILISATION
# =============================================================================
#
# D√âMARRAGE RAPIDE :
# 1. Activer √©tapes essentielles : 3.2, 3.3, 3.4, 3.7, 3.8, 3.9, 3.10
# 2. D√©sactiver √©tapes avanc√©es : 3.5 (LLM), 3.6 (Hybrid) (si latence critique)
#
# OPTIMISATION LATENCE :
# - D√©sactiver : LLM reranking (3.5), Hybrid fusion (3.6)
# - Activer : Adaptive filtering (3.8) pour r√©duire docs
#
# OPTIMISATION QUALIT√â :
# - Activer : LLM reranking (3.5), Hybrid fusion (3.6)
# - Utiliser : LLM sur top-10 uniquement
# - Consid√©rer : Activation conditionnelle LLM (queries complexes)
#
# MONITORING :
# - Activer : Quality validation (3.10), Metrics
# - Export : Prometheus pour dashboards
#
# =============================================================================
