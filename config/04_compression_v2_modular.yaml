# =============================================================================
# √âTAPE 04 v2 : COMPRESSION CONTEXTUELLE - CONFIGURATION MODULAIRE
# =============================================================================
# Configuration avec activation/d√©sactivation GRANULAIRE de chaque sous-√©tape.
#
# NOUVEAUT√â v2.1 :
# - Section MASTER CONFIG : activer/d√©sactiver chaque √©tape facilement
# - FLAGS GRANULAIRES : contr√¥le fin de chaque feature
# - PRESETS : configurations pr√©d√©finies (minimal, balanced, maximal, cost_optimized)
# - Matrice de d√©pendances : validation automatique
# =============================================================================

# =============================================================================
# ‚öôÔ∏è MASTER CONFIGURATION - ACTIVATION/D√âSACTIVATION GRANULAIRE
# =============================================================================

step_04_config:
  mode: "preset"  # "preset" ou "custom"
  preset: "balanced"  # "minimal", "balanced", "maximal", "cost_optimized"

  # ---------------------------------------------------------------------------
  # FLAGS D'ACTIVATION GRANULAIRE (si mode="custom")
  # ---------------------------------------------------------------------------

  # [4.1] Pre-Compression Analysis
  step_4_1_analysis:
    enabled: true                          # ‚≠ê Recommand√©
    complexity_analysis: true              # Densit√© info
    compressibility_score: true            # Facilit√© compression
    entity_density: true                   # Densit√© entit√©s
    redundancy_detection: true             # Overlap docs

  # [4.2] Selective Compression (RECOMP)
  step_4_2_selective:
    enabled: false                         # ‚ö†Ô∏è D√©sactiv√© (tr√®s agressif)
    extractive: true                       # S√©lection sentences
    abstractive: false                     # R√©sum√©s T5 (tr√®s lent)
    hybrid: false                          # Combine extractive+abstractive

  # [4.3] Prompt Compression (LLMLingua)
  step_4_3_llmlingua:
    enabled: true                          # ‚≠ê‚≠ê HIGH IMPACT
    tool: "llmlingua2"                     # llmlingua/longllmlingua/llmlingua2
    compression_rate: 0.4                  # 2.5x (0.4), 4x (0.25), 10x (0.1)
    preserve_entities: true                # Pr√©server entit√©s
    preserve_structure: false              # false = plus agressif
    budget_controller: true                # Ajuster selon context window

  # [4.4] Contextual Compression
  step_4_4_contextual:
    enabled: true                          # ‚≠ê Recommand√©
    method: "extractive"                   # extractive/abstractive/llm_based
    adaptive_passage_length: true          # Adapter selon complexity
    multi_doc_summary: false               # R√©sum√©s cross-docs (optionnel)

  # [4.5] Token-Level Compression
  step_4_5_token:
    enabled: false                         # ‚ö†Ô∏è Exp√©rimental
    method: "classification"               # classification/importance_scoring
    token_classification: false            # BERT classifier
    importance_scoring: false              # Attention/gradient/TF-IDF

  # [4.6] MMR with Compression Awareness
  step_4_6_mmr:
    enabled: true                          # ‚≠ê‚≠ê Important
    adaptive_lambda: true                  # Lambda selon query type
    compression_aware: true                # Boost docs bien compress√©s
    final_top_k: 15                        # Nombre docs final

  # [4.7] Quality Validation Post-Compression
  step_4_7_validation:
    enabled: true                          # ‚≠ê‚≠ê‚≠ê OBLIGATOIRE
    semantic_similarity: true              # Original vs compress√©
    entity_preservation: true              # Entit√©s conserv√©es
    answer_coverage: true                  # R√©ponse possible
    compression_ratio_check: true          # Dans bounds
    recompression: true                    # R√©essayer si fail

  # [4.8] Context Window Optimization
  step_4_8_context_window:
    enabled: true                          # ‚≠ê Recommand√©
    dynamic_allocation: true               # Allouer tokens intelligemment
    smart_truncate: true                   # Truncate intelligently
    token_budget_management: true          # G√©rer budget
    multi_turn_awareness: false            # Historique conversation (optionnel)

# =============================================================================
# üì¶ PRESETS DE CONFIGURATION
# =============================================================================

presets:
  # ---------------------------------------------------------------------------
  # PRESET : minimal
  # ---------------------------------------------------------------------------
  minimal:
    description: "Compression minimale - Latence prioritaire"
    latency_target_ms: 200
    compression_ratio: 2x
    quality_gain: "+5%"

    enabled_steps:
      step_4_1_analysis:
        enabled: false                     # D√©sactiv√© (latence)

      step_4_2_selective:
        enabled: false

      step_4_3_llmlingua:
        enabled: false                     # D√©sactiv√© (latence)

      step_4_4_contextual:
        enabled: true
        method: "extractive"
        adaptive_passage_length: false
        multi_doc_summary: false

      step_4_5_token:
        enabled: false

      step_4_6_mmr:
        enabled: true
        adaptive_lambda: false
        compression_aware: false

      step_4_7_validation:
        enabled: true
        semantic_similarity: true
        entity_preservation: false
        answer_coverage: false
        recompression: false

      step_4_8_context_window:
        enabled: true
        dynamic_allocation: false
        smart_truncate: false

  # ---------------------------------------------------------------------------
  # PRESET : balanced ‚≠ê (Recommand√©)
  # ---------------------------------------------------------------------------
  balanced:
    description: "√âquilibre qualit√©/co√ªt/latence"
    latency_target_ms: 385
    compression_ratio: 2.5x
    quality_gain: "+15%"
    cost_reduction: "-20% tokens"

    enabled_steps:
      step_4_1_analysis:
        enabled: true                      # ‚úÖ Analyse pr√©-compression
        complexity_analysis: true
        compressibility_score: true
        entity_density: true
        redundancy_detection: true

      step_4_2_selective:
        enabled: false                     # D√©sactiv√© (trop agressif)

      step_4_3_llmlingua:
        enabled: true                      # ‚úÖ LLMLingua-2
        tool: "llmlingua2"
        compression_rate: 0.4              # 2.5x compression
        preserve_entities: true
        preserve_structure: false
        budget_controller: true

      step_4_4_contextual:
        enabled: true
        method: "extractive"
        adaptive_passage_length: true      # ‚úÖ Adaptatif
        multi_doc_summary: false

      step_4_5_token:
        enabled: false                     # Exp√©rimental

      step_4_6_mmr:
        enabled: true
        adaptive_lambda: true              # ‚úÖ Lambda adaptatif
        compression_aware: true            # ‚úÖ Compression-aware
        final_top_k: 15

      step_4_7_validation:
        enabled: true                      # ‚úÖ Validation compl√®te
        semantic_similarity: true
        entity_preservation: true
        answer_coverage: true
        compression_ratio_check: true
        recompression: true

      step_4_8_context_window:
        enabled: true
        dynamic_allocation: true           # ‚úÖ Allocation dynamique
        smart_truncate: true
        token_budget_management: true

  # ---------------------------------------------------------------------------
  # PRESET : maximal (Qualit√© & compression maximales)
  # ---------------------------------------------------------------------------
  maximal:
    description: "Compression agressive + qualit√© maximale"
    latency_target_ms: 900
    compression_ratio: 4x-10x
    quality_gain: "+35%"
    cost_reduction: "-75% √† -90% tokens"

    enabled_steps:
      step_4_1_analysis:
        enabled: true
        complexity_analysis: true
        compressibility_score: true
        entity_density: true
        redundancy_detection: true

      step_4_2_selective:
        enabled: true                      # ‚úÖ RECOMP activ√©
        extractive: true
        abstractive: true                  # ‚úÖ R√©sum√©s abstractifs
        hybrid: false

      step_4_3_llmlingua:
        enabled: true
        tool: "longllmlingua"              # ‚úÖ LongLLMLingua (meilleur)
        compression_rate: 0.25             # 4x compression
        preserve_entities: true
        preserve_structure: false
        budget_controller: true

      step_4_4_contextual:
        enabled: true
        method: "extractive"
        adaptive_passage_length: true
        multi_doc_summary: true            # ‚úÖ Multi-doc summary

      step_4_5_token:
        enabled: false                     # Exp√©rimental

      step_4_6_mmr:
        enabled: true
        adaptive_lambda: true
        compression_aware: true
        final_top_k: 15

      step_4_7_validation:
        enabled: true
        semantic_similarity: true
        entity_preservation: true
        answer_coverage: true
        compression_ratio_check: true
        recompression: true

      step_4_8_context_window:
        enabled: true
        dynamic_allocation: true
        smart_truncate: true
        token_budget_management: true
        multi_turn_awareness: false

  # ---------------------------------------------------------------------------
  # PRESET : cost_optimized (Minimiser co√ªts tokens)
  # ---------------------------------------------------------------------------
  cost_optimized:
    description: "Compression ultra-agressive pour co√ªts minimaux"
    latency_target_ms: 600
    compression_ratio: 5x-10x
    quality_gain: "+10%"
    cost_reduction: "-80% √† -90% tokens"

    enabled_steps:
      step_4_1_analysis:
        enabled: false                     # D√©sactiv√© (latence)

      step_4_2_selective:
        enabled: true                      # ‚úÖ RECOMP extractive
        extractive: true
        abstractive: false                 # Trop lent
        hybrid: false

      step_4_3_llmlingua:
        enabled: true
        tool: "llmlingua2"
        compression_rate: 0.2              # ‚úÖ 5x compression agressif
        preserve_entities: true
        preserve_structure: false
        budget_controller: true

      step_4_4_contextual:
        enabled: false                     # D√©sactiv√© (LLMLingua suffit)

      step_4_5_token:
        enabled: false

      step_4_6_mmr:
        enabled: true
        adaptive_lambda: false
        compression_aware: false
        final_top_k: 12                    # Moins de docs

      step_4_7_validation:
        enabled: false                     # D√©sactiv√© (latence)

      step_4_8_context_window:
        enabled: true
        dynamic_allocation: true
        smart_truncate: true

# =============================================================================
# üìä MATRICE DE D√âPENDANCES
# =============================================================================

dependencies:
  step_4_1_analysis.complexity_analysis:
    optional:
      - "Phase 01: step_1_1_query_understanding"

  step_4_3_llmlingua:
    requires:
      - "LLMLingua library installed (pip install llmlingua)"
    warning: "N√©cessite llmlingua, llmlingua2 ou longllmlingua"

  step_4_6_mmr.adaptive_lambda:
    requires:
      - "Phase 01: step_1_1_query_understanding.type_classification"
    warning: "Adaptive lambda n√©cessite query type"

  step_4_6_mmr.compression_aware:
    requires:
      - step_4_3_llmlingua OR step_4_4_contextual
    warning: "Compression-aware n√©cessite compression active"

  step_4_7_validation.answer_coverage:
    requires:
      - "LLM pour v√©rifier answerability"
    optional:
      - step_4_7_validation.semantic_similarity

  step_4_8_context_window.token_budget_management:
    requires:
      - "tiktoken library (pip install tiktoken)"

# =============================================================================
# üîç VALIDATION DE CONFIGURATION
# =============================================================================

validation:
  enabled: true
  on_missing_dependency: "warn"
  on_invalid_config: "error"

  checks:
    - "check_dependencies"
    - "check_library_availability"  # LLMLingua, tiktoken
    - "check_compression_ratio_realistic"
    - "check_context_window_size"

# =============================================================================
# üêõ MODE DEBUG
# =============================================================================

debug:
  enabled: false
  log_level: "DEBUG"
  log_substeps: true
  include_compression_stats: true

  latency_alerts:
    step_4_1: 25
    step_4_2: 600    # RECOMP abstractive tr√®s lent
    step_4_3: 200    # LLMLingua
    step_4_4: 120
    step_4_5: 100
    step_4_6: 40
    step_4_7: 40
    step_4_8: 20

# =============================================================================
# üíæ CONFIGURATION D√âTAILL√âE DES SOUS-√âTAPES
# =============================================================================

# [4.1] Pre-Compression Analysis
pre_compression_analysis:
  complexity_analysis:
    metrics: ["info_density", "vocabulary_diversity"]
  compressibility_score:
    method: "entropy"
  entity_density:
    ner_model: "fr_core_news_md"

# [4.2] Selective Compression (RECOMP)
selective_compression:
  extractive:
    max_sentences_per_doc: 3
    relevance_threshold: 0.7
  abstractive:
    model: "t5-base"
    target_length: 100

# [4.3] Prompt Compression (LLMLingua)
prompt_compression:
  llmlingua2:
    compression_rate: 0.4  # 2.5x
    preserve_named_entities: true
    preserve_structure: false
  longllmlingua:
    compression_rate: 0.25  # 4x
    question_aware: true
    boost_question_proximity: true

# [4.4] Contextual Compression
contextual_compression:
  extractive:
    scorer_model: "BAAI/bge-m3"
    max_passage_length: 200
    relevance_threshold: 0.4
    adaptive_passage_length:
      by_complexity: {simple: 100, medium: 200, complex: 300}

# [4.6] MMR
mmr:
  adaptive_lambda:
    by_query_type: {factual: 0.7, analytical: 0.5, comparative: 0.6}
    default: 0.6
  compression_aware:
    boost_well_compressed: true
    compression_loss_weight: 0.2
  final_top_k: 15

# [4.7] Quality Validation
quality_validation:
  semantic_similarity:
    min_similarity: 0.85
    action: "warn"
  entity_preservation:
    min_coverage: 0.9
    action: "warn"
  answer_coverage:
    verify_answerability: true
  recompression:
    max_attempts: 2

# [4.8] Context Window Optimization
context_window_optimization:
  max_context_tokens: 100000
  dynamic_allocation:
    allocation_strategy: "ranked"
    top_k_boost: 1.5
  smart_truncate:
    priority: "relevance"
    preserve_top_k: 5
  token_budget:
    strategy: "proportional"
    reserve_for_answer: 2000

# =============================================================================
# üìù NOTES D'UTILISATION
# =============================================================================
#
# D√âMARRAGE RAPIDE :
#
# 1. Mode Preset (Recommand√©) :
#    step_04_config:
#      mode: "preset"
#      preset: "balanced"  # ‚≠ê Recommand√©
#
# 2. Mode Custom (Contr√¥le granulaire) :
#    step_04_config:
#      mode: "custom"
#      step_4_3_llmlingua:
#        enabled: true
#        compression_rate: 0.4  # 2.5x compression
#
# CONTR√îLE GRANULAIRE AVANC√â :
#
# # LLMLingua agressif (4x compression)
# step_04_config:
#   step_4_3_llmlingua:
#     enabled: true
#     compression_rate: 0.25  # 4x
#     preserve_structure: false  # Plus agressif
#
# # RECOMP extractive uniquement (rapide)
# step_04_config:
#   step_4_2_selective:
#     enabled: true
#     extractive: true
#     abstractive: false  # D√©sactiver (lent)
#
# # MMR adaptatif avec compression awareness
# step_04_config:
#   step_4_6_mmr:
#     enabled: true
#     adaptive_lambda: true
#     compression_aware: true
#
# OPTIMISATION PAR USE CASE :
#
# - FAQ/Support : preset="minimal" (2x, 200ms, +5%)
# - Entreprise : preset="balanced" (2.5x, 385ms, +15%, -20% co√ªt)
# - Long Context : preset="maximal" (4x-10x, 900ms, +35%, -75% co√ªt)
# - Cost-Sensitive : preset="cost_optimized" (5x-10x, 600ms, +10%, -80% co√ªt)
#
# =============================================================================
