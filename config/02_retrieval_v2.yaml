# =============================================================================
# √âTAPE 02 v2 : RETRIEVAL AVANC√â - ARCHITECTURE 12 SOUS-√âTAPES (RAG ULTIME 2025+)
# =============================================================================
# Pipeline retrieval enrichi combinant routing adaptatif, pre-filtering metadata,
# triple hybrid retrieval, cache intelligent, et strat√©gies de fallback.
#
# ARCHITECTURE v2 (12 SOUS-√âTAPES) :
# 2.1  ‚Üí Query Understanding & Routing
# 2.2  ‚Üí Metadata Extraction & Filtering
# 2.3  ‚Üí Adaptive Retrieval Strategy
# 2.4  ‚Üí Dense Retrieval (Enhanced)
# 2.5  ‚Üí Sparse Retrieval (Enhanced)
# 2.6  ‚Üí Late Interaction (Enhanced)
# 2.7  ‚Üí Multi-Index Retrieval
# 2.8  ‚Üí Cache & Deduplication
# 2.9  ‚Üí Results Fusion
# 2.10 ‚Üí Quality Validation
# 2.11 ‚Üí Fallback Strategies
# 2.12 ‚Üí Performance Monitoring
#
# GAINS ATTENDUS :
# - Qualit√© : +45-60% recall/precision vs v1
# - Latence : -15% avg (cache hit : -90%)
# - Robustesse : fallback si r√©sultats insuffisants
# - Monitoring : breakdown d√©taill√© latence + qualit√©
#
# COMPATIBILIT√â :
# - Backward compatible avec v1 (d√©sactiver √©tapes 2.1-2.3, 2.7, 2.10-2.12)
# =============================================================================

# =============================================================================
# 2.1 QUERY UNDERSTANDING & ROUTING ‚ú® NEW
# =============================================================================
# Analyse la query et route vers la meilleure strat√©gie de retrieval.
#
# OBJECTIFS :
# - Classifier le TYPE de query (factual, analytical, conversational, etc.)
# - D√©terminer les POIDS optimal pour chaque retriever
# - Router vers index sp√©cialis√©s si applicable
#
# GAINS :
# - +25% qualit√© sur queries sp√©cialis√©es
# - -30% latence (√©viter retrievers inutiles)
#
# LATENCE : +10ms
# =============================================================================
query_routing:
  enabled: true

  # ---------------------------------------------------------------------------
  # CLASSIFICATION
  # ---------------------------------------------------------------------------
  classification:
    # Classifier √† utiliser
    # Options : "heuristic" (r√®gles), "llm" (LLM)
    classifier: "heuristic"

    # Configuration heuristic (rapide, pas de ML)
    heuristic:
      rules:
        factual:
          patterns: ["^(qui|quoi|quel|quelle|quand|o√π|combien|how many|what|when|where)"]
          keywords: ["d√©finition", "c'est quoi", "definition", "what is"]
        analytical:
          patterns: ["^(pourquoi|comment|why|how|explain)"]
          keywords: ["analyse", "explain", "reasoning", "cause"]
        conversational:
          patterns: ["^(peux-tu|pourrais-tu|can you|could you)"]
          keywords: ["aide-moi", "help me", "je veux", "I want"]
        navigational:
          keywords: ["document", "page", "fichier", "file", "t√©l√©charger", "download"]
        comparative:
          keywords: ["diff√©rence", "comparaison", "vs", "versus", "compare"]

    # Configuration LLM (tr√®s pr√©cis, lent)
    llm:
      provider: "ollama"
      model: "qwen2.5:7B"
      temperature: 0.0
      prompt_template: |
        Classifie le type de la requ√™te suivante parmi : factual, analytical, conversational, navigational, comparative.
        R√©ponds avec un seul mot.

        Requ√™te : {query}
        Type :

  # ---------------------------------------------------------------------------
  # ROUTING RULES
  # ---------------------------------------------------------------------------
  # Poids pour chaque retriever selon le type de query
  # Somme des poids doit faire 1.0
  routing_rules:
    factual:
      # Queries factuelles : privil√©gier BM25 (exact match)
      dense_weight: 0.3
      sparse_weight: 0.5
      late_weight: 0.2
      description: "Exact match important (noms, dates)"

    analytical:
      # Queries analytiques : privil√©gier dense (s√©mantique)
      dense_weight: 0.5
      sparse_weight: 0.2
      late_weight: 0.3
      description: "Compr√©hension s√©mantique critique"

    conversational:
      # Queries conversationnelles : √©quilibr√©
      dense_weight: 0.4
      sparse_weight: 0.3
      late_weight: 0.3
      description: "Approche √©quilibr√©e"

    navigational:
      # Queries navigational : BM25 dominant
      dense_weight: 0.2
      sparse_weight: 0.7
      late_weight: 0.1
      description: "Recherche documents sp√©cifiques"

    comparative:
      # Queries comparatives : ColBERT + dense
      dense_weight: 0.4
      sparse_weight: 0.2
      late_weight: 0.4
      description: "Contexte et reasoning importants"

  # ---------------------------------------------------------------------------
  # RETRIEVER SELECTION
  # ---------------------------------------------------------------------------
  # D√©sactiver retrievers si poids < threshold (optimisation latence)
  retriever_selection:
    enabled: true
    min_weight_threshold: 0.1  # D√©sactiver si poids < 10%
    # Exemple : factual ‚Üí late_weight=0.2 ‚Üí late disabled si threshold=0.25

# =============================================================================
# 2.2 METADATA EXTRACTION & FILTERING ‚ú® NEW
# =============================================================================
# Extrait metadata de la query et pr√©-filtre les index avant retrieval.
#
# OBJECTIFS :
# - Extraire TEMPORAL filters (dates, ann√©es, p√©riodes)
# - Extraire GEOGRAPHIC filters (pays, villes, r√©gions)
# - Extraire DOMAIN filters (finance, tech, legal)
# - Convertir langage naturel ‚Üí filtres structur√©s (Self-Query)
#
# GAINS (source : arxiv.org/abs/2510.24402) :
# - +15% Precision@5
# - +13% Recall@5
# - +16% MRR
# - -40% latence retrieval (moins de candidates)
#
# LATENCE : +25ms
# =============================================================================
metadata_filtering:
  enabled: true

  # ---------------------------------------------------------------------------
  # SELF-QUERY RETRIEVAL
  # ---------------------------------------------------------------------------
  # Convertit queries en langage naturel en filtres structur√©s
  # Exemple : "documents techniques de 2024" ‚Üí temporal_filter: year=2024, domain: tech
  self_query:
    enabled: true

    # Parser √† utiliser
    # Options : "rule_based" (regex), "llm" (LLM)
    parser: "llm"

    # Configuration rule-based
    rule_based:
      patterns:
        year: "\\b(19|20)\\d{2}\\b"
        country: "\\b(France|USA|UK|Germany|Spain)\\b"
        domain: "\\b(technique|financial|legal|medical)\\b"

    # Configuration LLM
    llm:
      provider: "ollama"
      model: "qwen2.5:7B"
      temperature: 0.0
      prompt_template: |
        Extrait les filtres metadata de la requ√™te suivante.
        R√©ponds en JSON avec les champs : temporal, geographic, domain, format.
        Si aucun filtre d√©tect√©, retourne null.

        Requ√™te : {query}
        Filtres JSON :

  # ---------------------------------------------------------------------------
  # TEMPORAL FILTERING
  # ---------------------------------------------------------------------------
  temporal_filtering:
    enabled: true

    # Extracteur de dates
    # Options : "dateparser", "regex", "ner"
    extractor: "dateparser"

    dateparser:
      languages: ["fr", "en"]
      settings:
        PREFER_DATES_FROM: "past"
        RELATIVE_BASE: "today"

    # Types de patterns d√©tect√©s
    patterns:
      - "date_point"        # "15 mars 2024"
      - "date_range"        # "entre 2020 et 2023"
      - "relative_date"     # "l'ann√©e derni√®re"
      - "period"            # "en 2024"

    # Normalisation
    normalize_to_iso: true

  # ---------------------------------------------------------------------------
  # GEOGRAPHIC FILTERING
  # ---------------------------------------------------------------------------
  geographic_filtering:
    enabled: true

    # Extracteur
    # Options : "ner" (spaCy), "gazetteer" (dictionnaire)
    extractor: "ner"

    # Configuration NER
    ner:
      model: "fr_core_news_md"
      entity_types: ["LOC", "GPE"]  # Location, Geopolitical Entity

    # Gazetteer (dictionnaire g√©ographique)
    gazetteer:
      path: "dictionaries/geographic_gazetteer.json"

    # R√©solution g√©ographique (pays ‚Üí continent, ville ‚Üí pays)
    geo_resolution:
      enabled: true
      hierarchy: ["city", "region", "country", "continent"]

    # Expansion hi√©rarchique
    # "Paris" ‚Üí ["Paris", "√éle-de-France", "France", "Europe"]
    expand_hierarchy: true

  # ---------------------------------------------------------------------------
  # DOMAIN FILTERING
  # ---------------------------------------------------------------------------
  domain_filtering:
    enabled: true

    # Classifier de domaine
    classifier:
      method: "keyword"  # ou "llm"

      # Domaines support√©s
      domains:
        - "finance"
        - "technology"
        - "healthcare"
        - "legal"
        - "science"
        - "education"
        - "business"
        - "general"

      # Mapping keywords ‚Üí domaine
      keyword_mapping:
        finance:
          - "banque"
          - "bourse"
          - "investissement"
          - "cr√©dit"
          - "finance"
        technology:
          - "tech"
          - "logiciel"
          - "AI"
          - "software"
          - "programming"
        healthcare:
          - "sant√©"
          - "m√©dical"
          - "health"
          - "medical"
          - "patient"
        legal:
          - "droit"
          - "loi"
          - "juridique"
          - "legal"
          - "law"

  # ---------------------------------------------------------------------------
  # FORMAT FILTERING
  # ---------------------------------------------------------------------------
  format_filtering:
    enabled: false  # D√©sactiv√© par d√©faut (peu fr√©quent)

    # Types de documents
    document_types:
      - "pdf"
      - "word"
      - "excel"
      - "powerpoint"
      - "image"
      - "code"

    # Patterns de d√©tection
    patterns:
      pdf: ["pdf", "document pdf"]
      word: ["doc", "docx", "document word"]
      excel: ["xls", "xlsx", "spreadsheet", "tableau"]
      powerpoint: ["ppt", "pptx", "pr√©sentation"]
      image: ["image", "photo", "png", "jpg"]
      code: ["code", "script", "source"]

  # ---------------------------------------------------------------------------
  # FILTER APPLICATION
  # ---------------------------------------------------------------------------
  filter_application:
    # Mode d'application
    # Options : "strict" (ET logique), "lenient" (OU logique)
    mode: "strict"

    # Comportement si aucun r√©sultat
    # Options : "relax" (rel√¢cher filtres), "keep" (garder vide)
    on_empty_results: "relax"

    # Ordre de relaxation des filtres (si on_empty_results=relax)
    relaxation_order:
      - "format_filter"      # Rel√¢cher en premier
      - "temporal_filter"
      - "domain_filter"
      - "geographic_filter"  # Rel√¢cher en dernier

# =============================================================================
# 2.3 ADAPTIVE RETRIEVAL STRATEGY ‚ú® NEW
# =============================================================================
# Adapte top_k et techniques selon complexit√© query et budget latence.
#
# OBJECTIFS :
# - Adapter TOP_K selon complexit√© (simple: 20, complex: 200)
# - S√©lectionner TECHNIQUES selon besoin (activer/d√©sactiver retrievers)
# - Allouer BUDGET LATENCE dynamiquement
#
# GAINS :
# - +10% qualit√© sur queries complexes
# - -35% latence sur queries simples
#
# LATENCE : +5ms
# =============================================================================
adaptive_retrieval:
  enabled: true

  # ---------------------------------------------------------------------------
  # ADAPTIVE TOP-K
  # ---------------------------------------------------------------------------
  top_k_strategy:
    # Auto-s√©lection bas√©e sur complexity_score (de Phase 01)
    auto: true

    # Mapping complexity ‚Üí top_k
    complexity_mapping:
      simple: 20      # complexity < 0.3
      medium: 100     # complexity 0.3-0.6
      complex: 200    # complexity > 0.6

    # Override manuel (si auto=false)
    default_top_k: 100

  # ---------------------------------------------------------------------------
  # TECHNIQUE SELECTION
  # ---------------------------------------------------------------------------
  technique_selection:
    # Auto-s√©lection bas√©e sur query type et quality threshold
    auto: true

    # Seuil de qualit√© minimum requis
    # Si qualit√© insuffisante ‚Üí activer techniques suppl√©mentaires
    min_quality_threshold: 0.7

    # Priorisation techniques
    # Ordre d'activation si qualit√© insuffisante
    priority_order:
      - "dense"       # Toujours activ√©
      - "sparse"      # Activ√© si factual/navigational
      - "late"        # Activ√© si analytical/comparative ou qualit√© faible

  # ---------------------------------------------------------------------------
  # LATENCY BUDGETING
  # ---------------------------------------------------------------------------
  latency_budget:
    enabled: true

    # Budget latence total (ms)
    total_ms: 300

    # Allocation par √©tape (ms)
    allocation:
      routing: 10
      metadata: 25
      adaptive: 5
      dense: 100
      sparse: 50
      late: 100
      cache: 5
      fusion: 20
      validation: 10
      monitoring: 5

    # Comportement si d√©passement budget
    # Options : "degrade" (d√©sactiver late), "continue" (ignorer)
    on_exceed: "degrade"

    # Degradation strategy
    degradation:
      # Si d√©passement ‚Üí d√©sactiver par ordre
      disable_order:
        - "late"        # D√©sactiver ColBERT en premier
        - "sparse"      # Puis BM25
        # Dense jamais d√©sactiv√© (obligatoire)

  # ---------------------------------------------------------------------------
  # EARLY STOPPING
  # ---------------------------------------------------------------------------
  early_stopping:
    enabled: true

    # Conditions d'arr√™t
    conditions:
      # Si score top-1 > threshold ‚Üí arr√™ter
      top_1_score_threshold: 0.95

      # Si N r√©sultats avec score > threshold ‚Üí arr√™ter
      min_quality_results: 5
      quality_threshold: 0.8

# =============================================================================
# 2.4 DENSE RETRIEVAL (Enhanced)
# =============================================================================
# Retrieval s√©mantique via embeddings vectoriels.
#
# AM√âLIORATIONS v2 :
# - Contextual embeddings (embedding metadata avec texte)
# - Multi-index support (index par domaine/langue)
# - Query expansion au moment du retrieval
#
# GAINS :
# - +12% qualit√© avec contextual embeddings
#
# LATENCE : 100ms (inchang√©)
# =============================================================================
dense_retrieval:
  enabled: true

  # ---------------------------------------------------------------------------
  # MOD√àLE
  # ---------------------------------------------------------------------------
  model:
    provider: "ollama"
    model_name: "bge-m3:latest"
    embedding_dim: 1024

  # ---------------------------------------------------------------------------
  # CONNECTION
  # ---------------------------------------------------------------------------
  # Connection to ChromaDB
  host: "localhost"
  port: 8000
  collection_name: "compliance_docs"

  # ---------------------------------------------------------------------------
  # TOP-K
  # ---------------------------------------------------------------------------
  # Note : peut √™tre overrid√© par adaptive_retrieval
  top_k: 100

  # ---------------------------------------------------------------------------
  # CONTEXTUAL EMBEDDINGS ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Embedding metadata avec texte pour am√©liorer matching
  contextual_embeddings:
    enabled: true

    # Champs metadata √† inclure
    metadata_fields:
      - "title"
      - "domain"
      - "date"
      - "author"

    # Template
    # {text} sera remplac√© par le texte du document
    # {metadata} sera remplac√© par les m√©tadonn√©es
    template: |
      {text}

      Metadata: {metadata}

  # ---------------------------------------------------------------------------
  # MULTI-INDEX ‚ú® NEW
  # ---------------------------------------------------------------------------
  multi_index:
    enabled: true

    # Liste des index
    indexes:
      - name: "main"
        description: "Index g√©n√©ral"
        language: "all"
        domain: "all"

      - name: "finance"
        description: "Documents financiers"
        language: "fr"
        domain: "finance"

      - name: "tech"
        description: "Documentation technique"
        language: "en"
        domain: "technology"

      - name: "legal"
        description: "Documents juridiques"
        language: "fr"
        domain: "legal"

      - name: "archives"
        description: "Documents anciens"
        temporal: "before_2020"

    # Strat√©gie de s√©lection index
    # Options : "metadata_based", "all", "manual"
    selection_strategy: "metadata_based"

  # ---------------------------------------------------------------------------
  # QUANTIZATION
  # ---------------------------------------------------------------------------
  quantization:
    enabled: true
    # Options : "none", "binary", "scalar", "product"
    method: "binary"
    # Binary quantization : 1024d float32 ‚Üí 128d binary = 8√ó compression

  # ---------------------------------------------------------------------------
  # QUERY EXPANSION ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Expansion au moment du retrieval (diff√©rent de Phase 01)
  query_expansion:
    enabled: false  # D√©sactiv√© par d√©faut (d√©j√† fait en Phase 01)

    # Expansion par synonymes
    synonyms:
      enabled: false
      source: "wordnet"

  # ---------------------------------------------------------------------------
  # ADVANCED
  # ---------------------------------------------------------------------------
  # Seuil de similarit√© minimum
  similarity_threshold: 0.5

  # Normalisation des embeddings
  normalize: true

  # Fine-tuning domaine (si mod√®le fine-tun√© disponible)
  fine_tuned: false
  fine_tuned_model_path: null

  # Latence cible (ms)
  latency_target_ms: 100

# =============================================================================
# 2.5 SPARSE RETRIEVAL (Enhanced)
# =============================================================================
# Keyword matching avec BM25.
#
# AM√âLIORATIONS v2 :
# - Adaptive parameters (k1/b selon type document)
# - Query expansion (synonymes, acronymes)
# - Entity boosting (boost entit√©s nomm√©es)
#
# GAINS :
# - +8% qualit√© avec expansion + boosting
#
# LATENCE : 50ms (inchang√©)
# =============================================================================
sparse_retrieval:
  enabled: true

  # ---------------------------------------------------------------------------
  # OUTIL
  # ---------------------------------------------------------------------------
  tool:
    # Options : "pyserini" (recommand√©), "elasticsearch", "rank_bm25"
    name: "pyserini"

  # ---------------------------------------------------------------------------
  # ALGORITHME
  # ---------------------------------------------------------------------------
  algorithm: "bm25"

  # ---------------------------------------------------------------------------
  # PARAM√àTRES BM25
  # ---------------------------------------------------------------------------
  params:
    # Standard parameters
    k1: 1.5   # Term frequency saturation
    b: 0.75   # Length normalization

  # ---------------------------------------------------------------------------
  # ADAPTIVE PARAMETERS ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Adapter k1/b selon type de document
  adaptive_params:
    enabled: true

    # Param√®tres par type de document
    params_by_type:
      short_docs:
        # Documents courts (< 500 tokens) : moins de normalisation
        k1: 1.2
        b: 0.5
        doc_length_threshold: 500

      long_docs:
        # Documents longs (> 500 tokens) : plus de normalisation
        k1: 1.5
        b: 0.75
        doc_length_threshold: 500

  # ---------------------------------------------------------------------------
  # TOP-K
  # ---------------------------------------------------------------------------
  # Note : peut √™tre overrid√© par adaptive_retrieval
  top_k: 100

  # ---------------------------------------------------------------------------
  # QUERY EXPANSION ‚ú® NEW
  # ---------------------------------------------------------------------------
  query_expansion:
    enabled: true

    # Sources d'expansion
    sources:
      - "synonyms"      # WordNet synonyms
      - "acronyms"      # Acronym expansion

    # Configuration synonyms
    synonyms:
      library: "nltk"
      wordnet_lang: "fra"
      max_synonyms_per_word: 2

    # Configuration acronyms
    acronyms:
      dictionary_path: "dictionaries/acronyms.json"
      bidirectional: true  # "AI" ‚Üí "Artificial Intelligence" et inverse

  # ---------------------------------------------------------------------------
  # ENTITY BOOSTING ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Boost entit√©s nomm√©es dans la query
  entity_boosting:
    enabled: true

    # Facteur de boost par type d'entit√©
    boost_factors:
      PERSON: 1.5
      ORG: 1.3
      LOC: 1.2
      DATE: 1.1
      PRODUCT: 1.4
      EVENT: 1.2
      MISC: 1.0

  # ---------------------------------------------------------------------------
  # ADVANCED
  # ---------------------------------------------------------------------------
  # Latence cible (ms)
  latency_target_ms: 50

# =============================================================================
# 2.6 LATE INTERACTION (Enhanced)
# =============================================================================
# Token-level matching avec ColBERT.
#
# AM√âLIORATIONS v2 (source : ColBERTv2 paper) :
# - Compression r√©siduelle : 6-10√ó r√©duction espace
# - Quantization : 256 bytes ‚Üí 36 bytes (2-bit)
# - Token pruning : √©liminer tokens non pertinents
# - Hard negative mining : am√©liorer qualit√©
#
# GAINS :
# - +8% qualit√© (denoised supervision)
# - -50% latence (200ms ‚Üí 100ms)
# - -85% m√©moire (256 bytes ‚Üí 36 bytes)
#
# LATENCE : 100ms (vs 200ms v1)
# =============================================================================
late_interaction:
  enabled: true

  # ---------------------------------------------------------------------------
  # MOD√àLE
  # ---------------------------------------------------------------------------
  model:
    name: "colbert-ir/colbertv2.0"
    token_embedding_dim: 128

  # ---------------------------------------------------------------------------
  # OP√âRATEUR
  # ---------------------------------------------------------------------------
  operator: "MaxSim"
  # MaxSim : max(sim(qt, dt)) pour chaque token query

  # ---------------------------------------------------------------------------
  # TOP-K
  # ---------------------------------------------------------------------------
  # Note : moins que dense/sparse car plus co√ªteux
  top_k: 50

  # ---------------------------------------------------------------------------
  # COMPRESSION R√âSIDUELLE ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Compression agressive pour r√©duire empreinte m√©moire
  compression:
    enabled: true

    # M√©thode de compression
    # Options : "residual" (recommand√©), "product", "scalar"
    method: "residual"

    # Quantization (bits per dimension)
    # Options : 1 (20 bytes), 2 (36 bytes), 8 (256 bytes)
    quantization_bits: 2

    # Centroids pour compression r√©siduelle
    num_centroids: 256

  # ---------------------------------------------------------------------------
  # TOKEN PRUNING ‚ú® NEW
  # ---------------------------------------------------------------------------
  # √âliminer tokens non pertinents pour r√©duire compute
  token_pruning:
    enabled: true

    # Threshold de pruning (0-1)
    # Tokens avec score < threshold sont √©limines
    pruning_threshold: 0.1

    # M√©thode de scoring
    # Options : "attention", "magnitude", "learned"
    scoring_method: "attention"

  # ---------------------------------------------------------------------------
  # TRAINING ENHANCEMENTS ‚ú® NEW
  # ---------------------------------------------------------------------------
  training:
    # Hard negative mining
    # Am√©liore discrimination entre docs pertinents/non pertinents
    hard_negative_mining:
      enabled: false  # N√©cessite retraining
      num_negatives: 5

    # Denoised supervision (distillation teacher model)
    denoised_supervision:
      enabled: false  # N√©cessite teacher model
      teacher_model: "colbert-large"
      temperature: 2.0

  # ---------------------------------------------------------------------------
  # ADVANCED
  # ---------------------------------------------------------------------------
  # Fine-tuning domaine
  fine_tuned: false
  fine_tuned_model_path: null

  # Latence cible (ms)
  latency_target_ms: 100

# =============================================================================
# 2.7 MULTI-INDEX RETRIEVAL ‚ú® NEW
# =============================================================================
# Retrieval sur index sp√©cialis√©s selon domaine/langue/type.
#
# OBJECTIFS :
# - Index par DOMAINE (finance, tech, legal)
# - Index par LANGUE (fr, en, es)
# - Index par TYPE (code, documentation, blog)
# - Index TEMPOREL (archives, recent)
#
# GAINS :
# - +20% pr√©cision sur queries domaine-sp√©cifiques
# - -25% latence (indexes plus petits)
#
# LATENCE : 0ms (int√©gr√© dans dense/sparse/late)
# =============================================================================
multi_index:
  enabled: true

  # ---------------------------------------------------------------------------
  # INDEX DEFINITIONS
  # ---------------------------------------------------------------------------
  indexes:
    # Index principal (g√©n√©ral)
    - name: "main"
      description: "Index g√©n√©ral tous domaines"
      language: "all"
      domain: "all"
      temporal: "all"
      priority: 1

    # Index sp√©cialis√©s par domaine
    - name: "finance"
      description: "Documents financiers"
      language: "fr"
      domain: "finance"
      priority: 10  # Priorit√© haute si domain=finance

    - name: "tech"
      description: "Documentation technique"
      language: "en"
      domain: "technology"
      priority: 10

    - name: "legal"
      description: "Documents juridiques"
      language: "fr"
      domain: "legal"
      priority: 10

    - name: "medical"
      description: "Documents m√©dicaux"
      language: "fr"
      domain: "healthcare"
      priority: 10

    # Index par langue
    - name: "english"
      description: "Documents anglais"
      language: "en"
      domain: "all"
      priority: 5

    - name: "french"
      description: "Documents fran√ßais"
      language: "fr"
      domain: "all"
      priority: 5

    # Index temporel
    - name: "recent"
      description: "Documents r√©cents (<1 an)"
      temporal: "after_2024"
      priority: 8

    - name: "archives"
      description: "Documents anciens (>3 ans)"
      temporal: "before_2021"
      priority: 3

  # ---------------------------------------------------------------------------
  # SELECTION STRATEGY
  # ---------------------------------------------------------------------------
  selection_strategy:
    # Strat√©gie de s√©lection
    # Options : "metadata_based" (recommand√©), "all", "manual", "learned"
    method: "metadata_based"

    # Metadata-based selection
    metadata_based:
      # Utilise metadata extraits en 2.2 pour s√©lectionner index
      use_domain_filter: true
      use_language_filter: true
      use_temporal_filter: true

    # Fallback si aucun index sp√©cialis√© trouv√©
    fallback_to_main: true

    # Max nombre d'index √† interroger simultan√©ment
    max_indexes: 3

  # ---------------------------------------------------------------------------
  # FUSION STRATEGY
  # ---------------------------------------------------------------------------
  # Fusion r√©sultats cross-index
  fusion_strategy:
    # M√©thode de fusion
    # Options : "RRF", "weighted_sum", "priority_based"
    method: "priority_based"

    # Priority-based : index avec priority haute = poids plus √©lev√©
    priority_based:
      use_index_priority: true

    # RRF parameters
    rrf:
      k: 60

# =============================================================================
# 2.8 CACHE & DEDUPLICATION (Enhanced)
# =============================================================================
# Cache r√©sultats et √©limination doublons.
#
# AM√âLIORATIONS v2 :
# - Query similarity cache (cache si query similaire)
# - Result warming (pr√©-calcul queries fr√©quentes)
# - Adaptive TTL (TTL selon volatilit√©)
#
# GAINS :
# - -90% latence sur cache hit (300ms ‚Üí 30ms)
# - +30% throughput
#
# LATENCE : 0ms (hit) / 30ms (miss)
# =============================================================================
caching:
  enabled: true

  # ---------------------------------------------------------------------------
  # BACKEND
  # ---------------------------------------------------------------------------
  backend:
    # Options : "memory" (in-process), "redis" (distribu√©)
    type: "redis"

    # Configuration Redis
    redis:
      host: "localhost"
      port: 6379
      db: 0
      password: null

    # Configuration Memory
    memory:
      max_size: 10000  # Max queries en cache

  # ---------------------------------------------------------------------------
  # QUERY SIMILARITY CACHE ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Cache hit si query similaire (pas besoin match exact)
  query_similarity:
    enabled: true

    # Threshold de similarit√© (0-1)
    # Cache hit si similarity(query_new, query_cached) > threshold
    threshold: 0.95

    # M√©thode de calcul similarit√©
    # Options : "embedding" (BGE-M3), "edit_distance", "jaccard"
    method: "embedding"

    # Embedding model (si method=embedding)
    embedding_model: "bge-m3:latest"

  # ---------------------------------------------------------------------------
  # RESULT WARMING ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Pr√©-calculer r√©sultats pour queries fr√©quentes
  warming:
    enabled: true

    # Nombre de top queries √† warmer
    top_queries: 1000

    # Refresh interval
    refresh_interval: "1h"

    # Source des top queries
    # Options : "analytics", "manual"
    source: "analytics"

    # Fichier manuel (si source=manual)
    manual_queries_file: "config/top_queries.txt"

  # ---------------------------------------------------------------------------
  # TTL (Time To Live)
  # ---------------------------------------------------------------------------
  ttl:
    # TTL adaptatif selon volatilit√© donn√©es
    adaptive: true

    # TTL par d√©faut (secondes)
    default: 3600  # 1 heure

    # TTL par domaine (si adaptive=true)
    by_domain:
      finance: 1800      # 30 min (donn√©es volatiles)
      technology: 3600   # 1 heure
      legal: 7200        # 2 heures (donn√©es stables)
      general: 3600

    # TTL par temporal (si adaptive=true)
    by_temporal:
      recent: 1800       # 30 min (donn√©es r√©centes)
      archives: 86400    # 24 heures (archives stables)

  # ---------------------------------------------------------------------------
  # CACHE KEY
  # ---------------------------------------------------------------------------
  cache_key:
    # Composants du cache key
    components:
      - "query_text"
      - "language"
      - "domain"
      - "enabled_techniques"  # dense/sparse/late
      - "top_k"

# ---------------------------------------------------------------------------
# DEDUPLICATION
# ---------------------------------------------------------------------------
deduplication:
  enabled: true

  # Seuil de similarit√© pour consid√©rer 2 docs comme doublons
  similarity_threshold: 0.95

  # M√©thode de calcul similarit√©
  # Options : "cosine" (embeddings), "jaccard" (tokens), "edit_distance"
  method: "cosine"

  # Near-duplicate detection ‚ú® NEW
  # D√©tecte documents tr√®s similaires mais pas identiques
  near_duplicate_detection:
    enabled: true
    threshold: 0.90  # Plus permissif que duplication exacte

  # Strat√©gie de conservation (quel document garder)
  # Options : "first", "best_score", "most_recent"
  keep_strategy: "best_score"

# =============================================================================
# 2.9 RESULTS FUSION (Enhanced)
# =============================================================================
# Fusion r√©sultats des retrievers.
#
# AM√âLIORATIONS v2 :
# - Learned fusion (apprentissage poids optimaux)
# - Confidence scoring (score confiance par r√©sultat)
# - Multi-source fusion (fusion cross-index)
#
# GAINS :
# - +5% qualit√© avec learned fusion
#
# LATENCE : 20ms (inchang√©)
# =============================================================================
fusion:
  # ---------------------------------------------------------------------------
  # M√âTHODE
  # ---------------------------------------------------------------------------
  method: "RRF"
  # Options : "RRF" (recommand√©), "weighted_sum", "learned"

  # ---------------------------------------------------------------------------
  # TOP-K GLOBAL
  # ---------------------------------------------------------------------------
  # Nombre final de documents apr√®s fusion
  global_top_k: 100

  # ---------------------------------------------------------------------------
  # RRF (Reciprocal Rank Fusion)
  # ---------------------------------------------------------------------------
  rrf:
    # Param√®tre k (constante de lissage)
    k: 60
    # Score RRF : 1 / (k + rank)

  # ---------------------------------------------------------------------------
  # WEIGHTED SUM
  # ---------------------------------------------------------------------------
  # Poids pour chaque retriever
  # Note : peut √™tre overrid√© par query_routing (2.1)
  weighted_sum:
    weights:
      dense: 0.4
      sparse: 0.3
      late: 0.3
    # Somme doit faire 1.0

  # ---------------------------------------------------------------------------
  # LEARNED FUSION ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Apprentissage automatique des poids optimaux
  learned_fusion:
    enabled: false  # N√©cessite donn√©es labellis√©es

    # Mod√®le de fusion
    # Options : "linear", "xgboost", "neural"
    model: "xgboost"

    # Features utilis√©es
    features:
      - "dense_score"
      - "sparse_score"
      - "late_score"
      - "metadata_match"      # Si doc match metadata query
      - "query_type"          # Type de query
      - "query_complexity"    # Complexity score
      - "index_name"          # Index source

    # Mod√®le entra√Æn√©
    model_path: "models/fusion_model.pkl"

  # ---------------------------------------------------------------------------
  # CONFIDENCE SCORING ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Score de confiance par r√©sultat
  confidence_scoring:
    enabled: true

    # M√©thode de calcul
    # Options : "aggregation" (moyenne scores), "variance", "learned"
    method: "aggregation"

    # Aggregation : moyenne des scores des retrievers
    aggregation:
      # Poids par retriever
      weights:
        dense: 0.4
        sparse: 0.3
        late: 0.3

  # ---------------------------------------------------------------------------
  # MULTI-SOURCE FUSION ‚ú® NEW
  # ---------------------------------------------------------------------------
  # Fusion r√©sultats cross-index (si multi_index enabled)
  multi_source:
    enabled: true

    # Fusion cross-index
    cross_index_fusion: true

    # Boost si document pr√©sent dans plusieurs index
    multi_index_boost: 1.2

  # ---------------------------------------------------------------------------
  # ADVANCED
  # ---------------------------------------------------------------------------
  # Latence cible (ms)
  latency_target_ms: 20

# =============================================================================
# 2.10 QUALITY VALIDATION ‚ú® NEW
# =============================================================================
# V√©rification qualit√© r√©sultats avant reranking.
#
# OBJECTIFS :
# - RELEVANCE check : score minimum requis
# - DIVERSITY check : √©viter r√©sultats trop similaires
# - COVERAGE check : r√©sultats couvrent aspects de la query
#
# GAINS :
# - +10% precision (√©limination faux positifs)
# - +12% diversity
#
# LATENCE : +10ms
# =============================================================================
quality_validation:
  enabled: true

  # ---------------------------------------------------------------------------
  # RELEVANCE CHECK
  # ---------------------------------------------------------------------------
  relevance_check:
    enabled: true

    # Score minimum requis
    min_score: 0.5

    # Action si score < min_score
    # Options : "filter" (√©liminer), "flag" (marquer), "reject" (erreur)
    action: "filter"

  # ---------------------------------------------------------------------------
  # DIVERSITY CHECK
  # ---------------------------------------------------------------------------
  diversity_check:
    enabled: true

    # M√©thode
    # Options : "mmr" (Maximal Marginal Relevance), "clustering", "similarity"
    method: "mmr"

    # MMR parameters
    mmr:
      lambda: 0.6  # Balance relevance (1.0) vs diversity (0.0)

    # Diversity minimale requise (0-1)
    min_diversity: 0.3

    # Action si diversity < min_diversity
    # Options : "rerank" (r√©ordre), "filter", "warn"
    action: "rerank"

  # ---------------------------------------------------------------------------
  # COVERAGE CHECK
  # ---------------------------------------------------------------------------
  coverage_check:
    enabled: true

    # Aspects de la query √† couvrir
    # Bas√© sur Phase 01 : entities, keywords, topics
    query_aspects:
      - "entities"       # Entit√©s nomm√©es
      - "keywords"       # Mots-cl√©s principaux
      - "topics"         # Topics principaux

    # Coverage minimale requise (0-1)
    # % des aspects couverts par au moins 1 document
    min_coverage: 0.7

    # Action si coverage < min_coverage
    # Options : "warn", "trigger_fallback", "continue"
    action: "warn"

  # ---------------------------------------------------------------------------
  # OUTLIER FILTERING
  # ---------------------------------------------------------------------------
  outlier_filtering:
    enabled: true

    # √âliminer r√©sultats avec score << moyenne
    # z-score threshold
    z_score_threshold: -2.0

# =============================================================================
# 2.11 FALLBACK STRATEGIES ‚ú® NEW
# =============================================================================
# Strat√©gies de secours si r√©sultats insuffisants.
#
# OBJECTIFS :
# - WEB SEARCH : fallback web si <5 r√©sultats
# - QUERY RELAXATION : rel√¢cher filtres progressivement
# - QUERY REFORMULATION : reformuler avec LLM
# - CROSS-LINGUAL : chercher autres langues
#
# GAINS :
# - +15% coverage (moins de queries sans r√©ponse)
#
# LATENCE : +0ms (si pas d√©clench√©), +500ms (si web search)
# =============================================================================
fallback:
  enabled: true

  # ---------------------------------------------------------------------------
  # TRIGGERS
  # ---------------------------------------------------------------------------
  # Conditions pour d√©clencher fallback
  triggers:
    # Nombre minimum de r√©sultats requis
    min_results: 5

    # Score moyen minimum requis
    min_avg_score: 0.6

    # Coverage minimale requise (de quality_validation)
    min_coverage: 0.7

  # ---------------------------------------------------------------------------
  # STRATEGIES
  # ---------------------------------------------------------------------------
  # Strat√©gies de fallback (ordre d'ex√©cution)
  strategies:
    # Strat√©gie 1 : Relax filters
    - type: "relax_filters"
      order: 1
      description: "Rel√¢cher filtres metadata progressivement"

      # Ordre de relaxation
      relax_sequence:
        - "format_filter"      # Rel√¢cher en premier (peu important)
        - "temporal_filter"
        - "domain_filter"
        - "geographic_filter"  # Rel√¢cher en dernier (important)

      # Stop si r√©sultats suffisants apr√®s chaque relaxation
      early_stop: true

    # Strat√©gie 2 : Query reformulation
    - type: "query_reformulation"
      order: 2
      description: "Reformuler query avec LLM"

      llm:
        provider: "ollama"
        model: "qwen2.5:7B"
        temperature: 0.3
        prompt_template: |
          La requ√™te suivante n'a pas donn√© de r√©sultats satisfaisants.
          Reformule-la de mani√®re plus g√©n√©rale pour √©largir la recherche.

          Requ√™te originale : {query}
          Requ√™te reformul√©e :

      # Nombre max de reformulations
      max_reformulations: 2

    # Strat√©gie 3 : Web search
    - type: "web_search"
      order: 3
      description: "Chercher sur le web (DuckDuckGo)"

      # Provider
      # Options : "duckduckgo", "google", "bing"
      provider: "duckduckgo"

      # Max r√©sultats √† r√©cup√©rer
      max_results: 10

      # Filtrer r√©sultats web selon domaine
      filter_by_domain: true

    # Strat√©gie 4 : Cross-lingual retrieval
    - type: "cross_lingual"
      order: 4
      description: "Chercher dans d'autres langues"

      # Langues cibles
      target_languages:
        - "en"
        - "es"
        - "de"

      # Traduire query
      translate_query: true

      # Traducteur
      translator:
        provider: "deepl"
        api_key: "${DEEPL_API_KEY}"

  # ---------------------------------------------------------------------------
  # FALLBACK RESULT MERGING
  # ---------------------------------------------------------------------------
  # Fusion r√©sultats fallback avec r√©sultats originaux
  result_merging:
    # M√©thode de fusion
    # Options : "append", "interleave", "weighted"
    method: "interleave"

    # Boost r√©sultats fallback
    # <1.0 : fallback moins prioritaire
    # >1.0 : fallback plus prioritaire
    fallback_boost: 0.8

# =============================================================================
# 2.12 PERFORMANCE MONITORING ‚ú® NEW
# =============================================================================
# Monitoring d√©taill√© latence et qualit√©.
#
# OBJECTIFS :
# - Latence par √©tape (breakdown d√©taill√©)
# - Quality metrics (recall, precision, MRR, nDCG)
# - Cache metrics (hit rate, miss rate)
# - Index metrics (size, update frequency)
#
# VALEUR :
# - Debugging : identification rapide probl√®mes
# - Optimisation : data-driven improvements
# - Alerting : d√©tection d√©gradations
#
# LATENCE : +5ms
# =============================================================================
monitoring:
  enabled: true

  # ---------------------------------------------------------------------------
  # LATENCY MONITORING
  # ---------------------------------------------------------------------------
  latency:
    enabled: true

    # Breakdown par sous-√©tape
    breakdown_by_step: true

    # M√©triques latence
    metrics:
      - "avg"          # Moyenne
      - "p50"          # M√©diane
      - "p95"          # Percentile 95
      - "p99"          # Percentile 99
      - "max"          # Maximum

    # Threshold d'alerte (ms)
    alert_threshold_ms: 500

    # Action si d√©passement
    # Options : "log", "alert", "degrade"
    on_exceed: "log"

  # ---------------------------------------------------------------------------
  # QUALITY MONITORING
  # ---------------------------------------------------------------------------
  quality:
    enabled: true

    # M√©triques qualit√©
    metrics:
      - "recall@10"
      - "recall@100"
      - "precision@5"
      - "precision@10"
      - "MRR"           # Mean Reciprocal Rank
      - "nDCG@10"       # Normalized Discounted Cumulative Gain

    # Fr√©quence de calcul
    # Options : "per_query", "batch", "hourly"
    compute_frequency: "per_query"

    # N√©cessite relevance judgments
    requires_labels: true

  # ---------------------------------------------------------------------------
  # CACHE MONITORING
  # ---------------------------------------------------------------------------
  cache:
    enabled: true

    # M√©triques cache
    metrics:
      - "hit_rate"      # % queries en cache
      - "miss_rate"     # % queries pas en cache
      - "eviction_rate" # % queries √©vinc√©es
      - "avg_ttl"       # TTL moyen

    # Fr√©quence de reporting
    report_frequency: "hourly"

  # ---------------------------------------------------------------------------
  # INDEX MONITORING
  # ---------------------------------------------------------------------------
  index:
    enabled: true

    # M√©triques index
    metrics:
      - "size"              # Taille index (GB)
      - "num_documents"     # Nombre documents
      - "update_frequency"  # Fr√©quence updates
      - "fragmentation"     # Fragmentation index

    # Alertes
    alerts:
      max_size_gb: 100
      max_fragmentation: 0.3

  # ---------------------------------------------------------------------------
  # EXPORT
  # ---------------------------------------------------------------------------
  export:
    enabled: true

    # Format d'export
    # Options : "prometheus", "json", "csv"
    format: "prometheus"

    # Endpoint Prometheus
    prometheus:
      enabled: true
      endpoint: "http://prometheus:9090"
      push_interval: "30s"

    # JSON export
    json:
      enabled: false
      output_path: "logs/metrics.json"

  # ---------------------------------------------------------------------------
  # LOGGING
  # ---------------------------------------------------------------------------
  logging:
    enabled: true

    # Niveau de logging
    # Options : "DEBUG", "INFO", "WARNING", "ERROR"
    level: "INFO"

    # Logger chaque query individuellement
    log_per_query: false

    # Inclure donn√©es interm√©diaires dans logs
    include_intermediate_data: false

# =============================================================================
# üèÅ CONFIGURATION GLOBALE
# =============================================================================

# Latence cible totale (ms)
global_latency_target_ms: 300

# Mode debug
debug:
  enabled: false
  verbose: false

# =============================================================================
# üìù NOTES D'UTILISATION
# =============================================================================
#
# D√âMARRAGE RAPIDE :
# 1. Activer √©tapes essentielles : 2.1, 2.2, 2.4, 2.5, 2.9, 2.12
# 2. D√©sactiver √©tapes avanc√©es : 2.6, 2.7, 2.11 (si latence critique)
# 3. Activer cache (2.8) pour production
#
# OPTIMISATION LATENCE :
# - D√©sactiver : late_interaction (2.6), fallback (2.11)
# - Activer : cache (2.8), adaptive_strategy (2.3)
# - R√©duire : top_k, latency_budget
#
# OPTIMISATION QUALIT√â :
# - Activer : toutes √©tapes
# - Augmenter : top_k (200), latency_budget (500ms)
# - Activer : learned_fusion, fallback strategies
#
# =============================================================================
