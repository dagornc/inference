# =============================================================================
# ÉTAPE 01 v2 : QUERY PROCESSING & EXPANSION AVANCÉ (RAG ULTIME 2025+)
# =============================================================================
# Pipeline enrichi de transformation et enrichissement de la requête utilisateur
# avec 10 sous-étapes pour maximiser la qualité du retrieval.
#
# ARCHITECTURE v2 (10 SOUS-ÉTAPES) :
# 1.1 → Query Understanding & Classification
# 1.2 → Query Preprocessing (correction, normalisation)
# 1.3 → Named Entity Recognition
# 1.4 → Query Decomposition
# 1.5 → Metadata Extraction
# 1.6 → Adaptive Query Expansion
# 1.7 → Multi-Representation Embedding
# 1.8 → Query Quality Validation
# 1.9 → Ranking Feedback Integration (RaFe)
# 1.10 → Query Packaging & Caching
#
# GAINS ATTENDUS :
# - Qualité : +40-60% recall/precision vs v1
# - Latence : +35-145ms (adaptative selon complexité)
# - Robustesse : gestion queries mal formées, complexes, multilingues
#
# COMPATIBILITÉ :
# - 100% backward compatible avec v1 (mode legacy)
# - Activation progressive des nouvelles features
# =============================================================================

# =============================================================================
# 1.1 QUERY UNDERSTANDING & CLASSIFICATION
# =============================================================================
# Analyse intelligente de la requête pour adapter le traitement.
#
# OBJECTIFS :
# - Identifier le TYPE de query (factual, analytical, conversational, etc.)
# - Détecter l'INTENTION (search, compare, explain, list, navigate)
# - Mesurer la COMPLEXITÉ (simple, medium, complex)
# - Détecter la LANGUE (auto-detect ou forcé)
#
# UTILITÉ :
# - Adapter stratégie d'expansion selon type
# - Allouer ressources selon complexité
# - Optimiser prompts selon intention
# =============================================================================
query_understanding:
  enabled: true  # Désactiver pour mode legacy v1

  # ---------------------------------------------------------------------------
  # CLASSIFICATION DE TYPE
  # ---------------------------------------------------------------------------
  type_classification:
    enabled: true

    # Classificateur
    # Options : "heuristic" (règles), "llm" (LLM)
    classifier: "heuristic"

    # Configuration heuristic (rapide, pas de ML)
    heuristic:
      # Règles de classification (patterns regex ou keywords)
      rules:
        factual:
          # Questions factuelles (qui, quoi, quand, où, combien)
          patterns: ["^(qui|quoi|quel|quelle|quand|où|combien|how many|what|when|where)"]
          keywords: ["définition", "c'est quoi", "definition", "what is"]

        analytical:
          # Questions d'analyse (pourquoi, comment)
          patterns: ["^(pourquoi|comment|why|how|explain)"]
          keywords: ["analyse", "explain", "reasoning", "cause"]

        conversational:
          # Questions conversationnelles
          patterns: ["^(peux-tu|pourrais-tu|can you|could you)"]
          keywords: ["aide-moi", "help me", "je veux", "I want"]

        navigational:
          # Recherche de document/page spécifique
          keywords: ["document", "page", "fichier", "file", "télécharger", "download"]

        comparative:
          # Comparaisons
          keywords: ["différence", "comparaison", "vs", "versus", "difference", "compare"]

    # Configuration LLM (très précis, lent)
    llm:
      provider: "ollama"
      model: "qwen2.5:7B"
      temperature: 0.0
      prompt_template: |
        Classifie le type de la requête suivante parmi : factual, analytical, conversational, navigational, comparative.
        Réponds avec un seul mot.

        Requête : {query}
        Type :

  # ---------------------------------------------------------------------------
  # DÉTECTION D'INTENTION
  # ---------------------------------------------------------------------------
  intent_detection:
    enabled: true

    # Méthode : "keyword" (rapide), "ml" (précis), "llm" (très précis)
    method: "keyword"

    # Intentions supportées
    intents:
      - search          # Recherche d'information
      - compare         # Comparaison d'éléments
      - explain         # Explication de concept
      - list            # Liste d'items
      - navigate        # Navigation vers document
      - summarize       # Résumé de contenu
      - analyze         # Analyse approfondie

    # Mapping keywords → intentions
    keyword_mapping:
      search: ["cherche", "trouve", "recherche", "find", "search", "look for"]
      compare: ["différence", "comparaison", "vs", "versus", "compare", "difference"]
      explain: ["explique", "pourquoi", "comment", "explain", "why", "how"]
      list: ["liste", "énumère", "quels sont", "list", "what are"]
      navigate: ["ouvre", "accède", "télécharge", "open", "access", "download"]
      summarize: ["résume", "synthèse", "summarize", "summary"]
      analyze: ["analyse", "évalue", "analyze", "evaluate"]

  # ---------------------------------------------------------------------------
  # MESURE DE COMPLEXITÉ
  # ---------------------------------------------------------------------------
  complexity_scoring:
    enabled: true

    # Facteurs de complexité
    factors:
      # Longueur de la query (en tokens)
      length:
        weight: 0.2
        thresholds:
          simple: 10      # < 10 tokens = simple
          medium: 25      # 10-25 tokens = medium
          complex: 25     # > 25 tokens = complex

      # Nombre de clauses/sous-questions
      num_clauses:
        weight: 0.3
        detect_connectors: ["et", "ou", "mais", "and", "or", "but"]

      # Présence d'entités nommées
      num_entities:
        weight: 0.2

      # Vocabulaire spécialisé
      specialized_vocab:
        weight: 0.2
        # Détection de termes techniques
        indicators: ["technique", "scientifique", "juridique", "médical"]

      # Ambiguïté sémantique
      ambiguity:
        weight: 0.1
        # Détection de termes ambigus
        ambiguous_terms: ["ça", "truc", "chose", "it", "thing", "stuff"]

    # Score final : 0-1 (0=simple, 1=très complexe)
    # Seuils pour classification
    thresholds:
      simple: 0.3
      medium: 0.6
      complex: 1.0

# =============================================================================
# 1.2 QUERY PREPROCESSING
# =============================================================================
# Nettoyage et normalisation de la requête avant expansion.
#
# OBJECTIFS :
# - Corriger fautes d'orthographe
# - Normaliser grammaire
# - Expander synonymes
# - Expander acronymes
# - Nettoyer caractères spéciaux
# =============================================================================
query_preprocessing:
  enabled: true

  # ---------------------------------------------------------------------------
  # CORRECTION ORTHOGRAPHIQUE
  # ---------------------------------------------------------------------------
  spell_correction:
    enabled: true

    # Correcteur
    # Options : "symspell" (rapide), "jamspell", "languagetool" (précis)
    corrector: "symspell"

    # SymSpell configuration
    symspell:
      dictionary_path: "dictionaries/frequency_dictionary_fr.txt"
      max_edit_distance: 2
      prefix_length: 7

    # Seuil de confiance minimum pour appliquer correction
    confidence_threshold: 0.7

    # Préserver les entités nommées (ne pas corriger)
    preserve_named_entities: true

  # ---------------------------------------------------------------------------
  # NORMALISATION GRAMMATICALE
  # ---------------------------------------------------------------------------
  grammar_normalization:
    enabled: true

    # Transformations
    operations:
      # Normaliser casse (lowercase sauf entités)
      normalize_case: true

      # Supprimer accents (optionnel, selon use case)
      remove_accents: false

      # Normaliser espaces multiples
      normalize_whitespace: true

      # Supprimer ponctuation superflue
      clean_punctuation: true

      # Lemmatisation (ramener mots à forme canonique)
      lemmatize:
        enabled: true
        # Librairie : "spacy", "nltk", "stanza"
        library: "spacy"
        model: "fr_core_news_sm"  # Pour français

  # ---------------------------------------------------------------------------
  # EXPANSION DE SYNONYMES
  # ---------------------------------------------------------------------------
  synonym_expansion:
    enabled: true

    # Source de synonymes
    # Options : "wordnet", "custom_dict", "embedding_similarity"
    source: "wordnet"

    # WordNet configuration
    wordnet:
      language: "fra"  # French WordNet
      pos_tags: ["NOUN", "VERB", "ADJ"]  # POS à expander

    # Dictionnaire personnalisé
    custom_dict:
      path: "dictionaries/synonyms_custom.json"
      # Format : {"word": ["synonym1", "synonym2", ...]}

    # Similarité embedding (pour synonymes contextuels)
    embedding_similarity:
      model: "bge-m3:latest"
      threshold: 0.85  # Similarité cosine minimale

    # Nombre maximum de synonymes par mot
    max_synonyms_per_word: 2

  # ---------------------------------------------------------------------------
  # EXPANSION D'ACRONYMES
  # ---------------------------------------------------------------------------
  acronym_expansion:
    enabled: true

    # Dictionnaire acronymes
    dictionary_path: "dictionaries/acronyms.json"
    # Format : {"RAG": "Retrieval Augmented Generation", "LLM": "Large Language Model"}

    # Détection contexte pour disambiguation
    context_aware: true

    # Expansion bidirectionnelle (acronyme ↔ forme longue)
    bidirectional: true

# =============================================================================
# 1.3 NAMED ENTITY RECOGNITION (NER)
# =============================================================================
# Extraction et tagging des entités nommées pour boosting.
#
# ENTITÉS :
# - PERSON : personnes
# - ORG : organisations
# - LOC : lieux/géographie
# - DATE : dates et périodes
# - PRODUCT : produits
# - EVENT : événements
# - MISC : autres entités
# =============================================================================
named_entity_recognition:
  enabled: true

  # ---------------------------------------------------------------------------
  # EXTRACTEUR NER
  # ---------------------------------------------------------------------------
  extractor:
    # Méthode : "spacy" (rapide), "transformers" (SOTA), "llm" (très précis)
    method: "spacy"

    # spaCy configuration
    spacy:
      model: "fr_core_news_md"  # Modèle français medium
      # Alternatives : "fr_core_news_lg" (large, plus précis)

    # Transformers configuration (SOTA)
    transformers:
      model: "Jean-Baptiste/camembert-ner"  # CamemBERT NER français
      device: "cpu"  # ou "cuda" si GPU disponible

    # LLM configuration
    llm:
      provider: "ollama"
      model: "qwen2.5:7B"
      prompt_template: |
        Extrais les entités nommées (personnes, organisations, lieux, dates, produits) de la requête suivante.
        Format : [TYPE: entité]

        Requête : {query}
        Entités :

  # ---------------------------------------------------------------------------
  # POST-PROCESSING
  # ---------------------------------------------------------------------------
  post_processing:
    # Normaliser les entités (casse, accents)
    normalize_entities: true

    # Résolution de coréférences (pronominal resolution)
    coreference_resolution:
      enabled: false  # Optionnel, coûteux

    # Linking vers knowledge base (entity linking)
    entity_linking:
      enabled: false  # Optionnel, nécessite KB
      knowledge_base: "wikidata"

  # ---------------------------------------------------------------------------
  # BOOSTING
  # ---------------------------------------------------------------------------
  # Utiliser les entités pour boosting au retrieval
  boosting:
    enabled: true

    # Poids de boost par type d'entité
    weights:
      PERSON: 1.5
      ORG: 1.3
      LOC: 1.2
      DATE: 1.1
      PRODUCT: 1.4
      EVENT: 1.2
      MISC: 1.0

# =============================================================================
# 1.4 QUERY DECOMPOSITION
# =============================================================================
# Décomposition de queries complexes en sous-questions.
#
# UTILITÉ :
# - Questions multi-parties → questions atomiques
# - Améliore recall sur queries complexes
# - Permet retrieval granulaire
# =============================================================================
query_decomposition:
  enabled: true

  # ---------------------------------------------------------------------------
  # DÉTECTION DE COMPLEXITÉ
  # ---------------------------------------------------------------------------
  # Décomposer uniquement si query complexe
  trigger:
    # Seuil de score de complexité (de 1.1)
    min_complexity_score: 0.6

    # Détection de connecteurs logiques
    detect_connectors: ["et", "ou", "puis", "ensuite", "and", "or", "then", "also"]

    # Nombre minimum de clauses pour décomposer
    min_clauses: 2

  # ---------------------------------------------------------------------------
  # MÉTHODE DE DÉCOMPOSITION
  # ---------------------------------------------------------------------------
  method:
    # Options : "rule_based" (rapide), "llm" (précis)
    type: "llm"

    # Rule-based (découpe selon connecteurs)
    rule_based:
      split_on: ["et", "ou", "and", "or"]
      preserve_context: true  # Garder contexte commun

    # LLM-based (intelligent decomposition)
    llm:
      provider: "ollama"
      model: "qwen2.5:7B"
      temperature: 0.0
      prompt_template: |
        Décompose la question complexe suivante en sous-questions simples et atomiques.
        Chaque sous-question doit être autonome et compréhensible indépendamment.
        Liste chaque sous-question sur une nouvelle ligne, sans numérotation.

        Question complexe : {query}
        Sous-questions :

  # ---------------------------------------------------------------------------
  # STRATÉGIE D'EXÉCUTION
  # ---------------------------------------------------------------------------
  execution_strategy:
    # "parallel" : toutes sous-questions en parallèle
    # "sequential" : sous-questions en séquence (si dépendances)
    mode: "parallel"

    # Fusionner résultats de toutes sous-questions
    merge_results: true

    # Méthode de fusion : "union", "intersection", "weighted"
    merge_method: "union"

# =============================================================================
# 1.5 METADATA EXTRACTION
# =============================================================================
# Extraction de métadonnées et filtres de la requête.
#
# MÉTADONNÉES EXTRAITES :
# - Temporal : dates, ranges, périodes
# - Geographic : lieux, régions
# - Domain : domaine/catégorie
# - Format : type de document souhaité
# =============================================================================
metadata_extraction:
  enabled: true

  # ---------------------------------------------------------------------------
  # FILTRES TEMPORELS
  # ---------------------------------------------------------------------------
  temporal_filters:
    enabled: true

    # Extracteur
    # Options : "dateparser" (robuste), "regex" (rapide), "llm"
    extractor: "dateparser"

    # dateparser configuration
    dateparser:
      languages: ["fr", "en"]
      # Patterns reconnus : "2024", "janvier 2024", "last month", "yesterday", etc.

    # Patterns à extraire
    patterns:
      - "date_point"        # Date exacte
      - "date_range"        # Plage de dates
      - "relative_date"     # Dates relatives (hier, la semaine dernière)
      - "period"            # Périodes (années 2000, 21ème siècle)

    # Normalisation des dates extraites
    normalize_to_iso: true

  # ---------------------------------------------------------------------------
  # FILTRES GÉOGRAPHIQUES
  # ---------------------------------------------------------------------------
  geographic_filters:
    enabled: true

    # Extracteur
    extractor: "ner"  # Réutilise NER (LOC entities)

    # Gazetteer (liste de lieux connus)
    gazetteer_path: "dictionaries/geographic_gazetteer.json"

    # Résolution géographique (pays → régions → villes)
    geo_resolution:
      enabled: true
      # Hiérarchie : continent > pays > région > ville

    # Expansion géographique
    # Ex : "Paris" → ajoute "France", "Île-de-France"
    expand_hierarchy: true

  # ---------------------------------------------------------------------------
  # FILTRES DE DOMAINE
  # ---------------------------------------------------------------------------
  domain_filters:
    enabled: true

    # Classification de domaine
    classifier:
      # Options : "keyword" (rapide), "ml" (précis)
      method: "keyword"

      # Domaines supportés
      domains:
        - "finance"
        - "technology"
        - "healthcare"
        - "legal"
        - "science"
        - "education"
        - "business"
        - "general"

      # Mapping keywords → domaines
      keyword_mapping:
        finance: ["banque", "bourse", "investissement", "finance", "bank", "stock"]
        technology: ["tech", "logiciel", "AI", "software", "programming"]
        healthcare: ["santé", "médical", "health", "medical", "doctor"]
        legal: ["loi", "juridique", "contrat", "law", "legal", "contract"]
        science: ["recherche", "étude", "research", "study", "scientific"]

  # ---------------------------------------------------------------------------
  # FILTRES DE FORMAT
  # ---------------------------------------------------------------------------
  format_filters:
    enabled: true

    # Détection de types de documents souhaités
    document_types:
      - "pdf"
      - "word"
      - "excel"
      - "powerpoint"
      - "image"
      - "video"
      - "audio"

    # Patterns de détection
    patterns:
      pdf: ["pdf", "document pdf"]
      word: ["doc", "docx", "document word"]
      excel: ["xls", "xlsx", "tableur", "spreadsheet"]
      image: ["image", "photo", "picture", "png", "jpg"]

# =============================================================================
# 1.6 ADAPTIVE QUERY EXPANSION
# =============================================================================
# Expansion adaptative selon type et complexité de la query.
#
# NOUVEAUTÉ v2 :
# - Sélection dynamique des techniques selon query type
# - Nombre de variantes adaptatif (1-7)
# - Prompts personnalisés selon domaine
# =============================================================================
adaptive_query_expansion:
  enabled: true

  # ---------------------------------------------------------------------------
  # STRATÉGIE ADAPTATIVE
  # ---------------------------------------------------------------------------
  strategy_selection:
    # Activer sélection automatique des techniques
    auto_select: true

    # Mapping : query type → techniques recommandées
    strategies:
      factual:
        techniques: ["rewrite", "multi_query"]
        num_variants: 3
        reason: "Questions factuelles bénéficient de reformulations simples"

      analytical:
        techniques: ["step_back", "decomposition", "hyde"]
        num_variants: 5
        reason: "Questions analytiques nécessitent contexte large"

      conversational:
        techniques: ["rewrite"]
        num_variants: 2
        reason: "Questions conversationnelles sont généralement claires"

      navigational:
        techniques: []  # Pas d'expansion
        num_variants: 1
        reason: "Recherche de document spécifique, expansion contre-productive"

      comparative:
        techniques: ["decomposition", "multi_query"]
        num_variants: 4
        reason: "Comparaisons nécessitent multiples angles"

    # Mapping : complexity → nombre de variantes
    complexity_mapping:
      simple: 2        # Queries simples : peu d'expansion
      medium: 4        # Queries moyennes : expansion modérée
      complex: 7       # Queries complexes : expansion maximale

  # ---------------------------------------------------------------------------
  # CONFIGURATION DES TECHNIQUES (Identique v1 + ajouts)
  # ---------------------------------------------------------------------------
  llm:
    provider: "ollama"
    model: "qwen2.5:7B"
    temperature: 0.0
    max_tokens: 200

  cache:
    enabled: true
    ttl_seconds: 3600
    max_size: 10000

  # Techniques disponibles
  techniques:
    # --- TECHNIQUES v1 (conservées) ---
    rewrite:
      enabled: true
      weight: 1.0

    hyde:
      enabled: true
      weight: 1.2  # Plus efficace, poids supérieur

    multi_query:
      enabled: true
      num_variants: 4
      weight: 1.0

    step_back:
      enabled: true
      weight: 1.1

    # --- NOUVELLES TECHNIQUES v2 ---

    # Query Refinement via Ranking Feedback (RaFe)
    rafe:
      enabled: false  # Nécessite retrieval results (étape 1.9)
      num_iterations: 2
      top_k_for_feedback: 10

    # Query Contextualization (historique conversation)
    contextualization:
      enabled: false  # Nécessite session history
      max_history_turns: 3

    # Query Simplification (pour queries trop complexes)
    simplification:
      enabled: true
      trigger_complexity: 0.8  # Si score > 0.8
      prompt_template: |
        Simplifie la question complexe suivante en une question plus claire et directe,
        tout en conservant l'intention principale.

        Question complexe : {query}
        Question simplifiée :

    # Sub-query Extraction (alternative à decomposition)
    subquery_extraction:
      enabled: true
      max_subqueries: 3

  # ---------------------------------------------------------------------------
  # PROMPTS PERSONNALISÉS PAR DOMAINE
  # ---------------------------------------------------------------------------
  domain_specific_prompts:
    enabled: true

    # Prompts spécialisés par domaine
    prompts:
      finance:
        hyde: |
          Vous êtes un expert financier. Rédigez un extrait de rapport financier qui
          répond exhaustivement à la question suivante. Utilisez un vocabulaire
          technique précis du domaine financier.

          Question : {query}

        multi_query: |
          Générez {num_variants} reformulations de cette question financière,
          en utilisant la terminologie et les angles d'analyse propres au secteur financier.

          Question : {query}

      technology:
        hyde: |
          Vous êtes un ingénieur logiciel expert. Rédigez une documentation technique
          qui répond à la question suivante avec précision technique.

          Question : {query}

      healthcare:
        hyde: |
          Vous êtes un professionnel de santé. Rédigez un extrait de documentation
          médicale qui répond à la question suivante de manière factuelle et précise.

          Question : {query}

      # Prompt générique (fallback)
      general:
        hyde: |
          Vous êtes un expert du domaine. Rédigez un document concis qui répond de
          manière exhaustive à la question suivante. Ce document sera utilisé pour
          trouver des informations similaires. Ne mentionnez pas que c'est un document hypothétique.

          Question : {query}

# =============================================================================
# 1.7 MULTI-REPRESENTATION EMBEDDING
# =============================================================================
# Génération de multiples représentations vectorielles de la query.
#
# REPRÉSENTATIONS :
# - Dense : embedding vectoriel dense (BGE-M3, 1024d)
# - Sparse : embedding vectoriel sparse (SPLADE, learned)
# - Late Interaction : token-level embeddings (ColBERT, 128d per token)
#
# AVANTAGES :
# - Dense : sémantique globale
# - Sparse : matching exact + importance apprise
# - Late : matching fin token-à-token
# =============================================================================
multi_representation_embedding:
  enabled: true

  # ---------------------------------------------------------------------------
  # DENSE EMBEDDING (v1 - conservé)
  # ---------------------------------------------------------------------------
  dense:
    enabled: true
    provider: "ollama"
    model: "bge-m3:latest"
    embedding_dim: 1024
    quantization: "binary"
    normalize: true  # L2 normalization

  # ---------------------------------------------------------------------------
  # SPARSE EMBEDDING (NOUVEAU v2)
  # ---------------------------------------------------------------------------
  sparse:
    enabled: true

    # Modèle sparse
    # Options : "splade" (SOTA), "bm25_weights", "tfidf"
    model: "splade"

    splade:
      # Modèle SPLADE (Sparse Lexical AnD Expansion)
      model_name: "naver/splade-cocondenser-ensembledistil"
      # Génère un vecteur sparse avec poids appris
      # Dimensionnalité : vocabulaire size (~30k)

      # Nombre maximum de tokens non-zéro
      max_nonzero_tokens: 256

      # Seuil d'activation minimum
      activation_threshold: 0.01

    # Alternative : BM25 weights (plus simple)
    bm25_weights:
      k1: 1.5
      b: 0.75

  # ---------------------------------------------------------------------------
  # LATE INTERACTION EMBEDDING (NOUVEAU v2)
  # ---------------------------------------------------------------------------
  late_interaction:
    enabled: true

    # Modèle ColBERT
    model: "colbert-ir/colbertv2.0"

    # Embedding par token (au lieu d'un seul vecteur)
    token_embedding_dim: 128

    # Nombre maximum de tokens
    max_query_tokens: 32

    # Padding/truncation
    padding: "max_length"

    # Compression résiduelle (réduction mémoire)
    compression:
      enabled: true
      method: "quantization"  # Binary ou scalar

  # ---------------------------------------------------------------------------
  # FUSION DES REPRÉSENTATIONS
  # ---------------------------------------------------------------------------
  # Comment combiner les différentes représentations au retrieval
  fusion_strategy:
    # Stratégie : "separate" (3 retrievals séparés puis fusion)
    #           "hybrid" (combinaison au niveau index)
    strategy: "separate"

    # Poids pour fusion finale (si nécessaire)
    weights:
      dense: 0.5
      sparse: 0.3
      late: 0.2

# =============================================================================
# 1.8 QUERY QUALITY VALIDATION
# =============================================================================
# Validation de la qualité des queries générées.
#
# OBJECTIFS :
# - Détecter queries incomplètes
# - Détecter ambiguïtés
# - Scorer cohérence sémantique
# - Filtrer variantes de mauvaise qualité
# =============================================================================
query_quality_validation:
  enabled: true

  # ---------------------------------------------------------------------------
  # COMPLÉTUDE (Completeness)
  # ---------------------------------------------------------------------------
  completeness_check:
    enabled: true

    # Critères de complétude
    criteria:
      # Query doit contenir au moins X tokens
      min_tokens: 3

      # Query doit contenir un verbe (pour questions)
      requires_verb: true

      # Query ne doit pas être trop courte
      min_chars: 10

    # Score minimum de complétude (0-1)
    min_score: 0.6

  # ---------------------------------------------------------------------------
  # AMBIGUÏTÉ (Ambiguity)
  # ---------------------------------------------------------------------------
  ambiguity_detection:
    enabled: true

    # Détection de termes ambigus
    ambiguous_terms:
      high_ambiguity: ["ça", "truc", "chose", "machin", "it", "thing", "stuff"]
      medium_ambiguity: ["là", "ici", "cela", "there", "here", "this"]

    # Score maximum d'ambiguïté acceptable (0-1)
    # Plus élevé = plus ambigu
    max_score: 0.5

    # Action si ambiguïté détectée
    # Options : "warn", "clarify" (demander clarification), "reject"
    action: "warn"

  # ---------------------------------------------------------------------------
  # COHÉRENCE SÉMANTIQUE
  # ---------------------------------------------------------------------------
  semantic_coherence:
    enabled: true

    # Méthode : "embedding_similarity" (rapide), "llm" (précis)
    method: "embedding_similarity"

    # Embedding similarity
    embedding_similarity:
      # Comparer query originale avec variantes
      model: "bge-m3:latest"

      # Seuil minimum de similarité
      # Variantes trop différentes = incohérentes
      min_similarity: 0.3

      # Seuil maximum de similarité
      # Variantes trop similaires = redondantes
      max_similarity: 0.95

    # LLM coherence scoring
    llm:
      provider: "ollama"
      model: "qwen2.5:7B"
      prompt_template: |
        Évalue la cohérence sémantique entre la question originale et sa variante.
        Score de 0 (totalement incohérent) à 10 (parfaitement cohérent).

        Question originale : {original_query}
        Variante : {variant_query}
        Score :

  # ---------------------------------------------------------------------------
  # FILTRAGE DES VARIANTES
  # ---------------------------------------------------------------------------
  variant_filtering:
    enabled: true

    # Supprimer variantes de mauvaise qualité
    filters:
      # Score de qualité minimum (composite)
      min_quality_score: 0.5

      # Supprimer doublons exacts
      remove_duplicates: true

      # Supprimer variantes quasi-identiques (> 95% similarité)
      remove_near_duplicates:
        enabled: true
        threshold: 0.95

    # Garantir un nombre minimum de variantes
    # Si filtrage trop agressif, garder les meilleures
    min_variants_to_keep: 2

# =============================================================================
# 1.9 RANKING FEEDBACK INTEGRATION (RaFe)
# =============================================================================
# Raffinement itératif basé sur les résultats du retrieval.
#
# NOTE : Cette étape s'exécute APRÈS le retrieval initial (Phase 02).
# Elle nécessite un aller-retour : Query → Retrieval → Feedback → Refined Query → Retrieval
#
# PRINCIPE :
# 1. Retrieval initial avec query v1
# 2. Analyse des top-K résultats
# 3. Extraction termes importants des bons résultats
# 4. Reformulation query avec ces termes (query v2)
# 5. Retrieval final avec query v2
# =============================================================================
ranking_feedback:
  enabled: false  # Désactiver si latence critique (ajoute +100-200ms)

  # ---------------------------------------------------------------------------
  # DÉCLENCHEMENT
  # ---------------------------------------------------------------------------
  trigger:
    # Activer RaFe uniquement si certain conditions
    conditions:
      # Si score de qualité des résultats initiaux < seuil
      min_initial_quality_score: 0.7

      # Si query de complexité >= seuil
      min_query_complexity: 0.5

    # Mode : "always", "conditional", "never"
    mode: "conditional"

  # ---------------------------------------------------------------------------
  # ANALYSE DES RÉSULTATS
  # ---------------------------------------------------------------------------
  result_analysis:
    # Nombre de top résultats à analyser
    top_k: 10

    # Extraction de termes importants
    term_extraction:
      # Méthode : "tfidf", "keybert", "llm"
      method: "tfidf"

      # Nombre de termes à extraire
      num_terms: 10

      # Filtrer stopwords
      filter_stopwords: true

  # ---------------------------------------------------------------------------
  # REFORMULATION
  # ---------------------------------------------------------------------------
  reformulation:
    # Stratégie : "term_injection" (ajouter termes), "rewrite" (réécrire)
    strategy: "term_injection"

    # LLM pour reformulation
    llm:
      provider: "ollama"
      model: "qwen2.5:7B"
      temperature: 0.1
      prompt_template: |
        Reformule la requête suivante en intégrant les termes importants extraits
        des meilleurs résultats de recherche. Conserve l'intention originale tout
        en enrichissant la requête.

        Requête originale : {original_query}
        Termes importants : {important_terms}
        Requête reformulée :

  # ---------------------------------------------------------------------------
  # ITÉRATIONS
  # ---------------------------------------------------------------------------
  iterations:
    # Nombre maximum d'itérations RaFe
    max_iterations: 2

    # Critère d'arrêt : si amélioration < seuil
    min_improvement_threshold: 0.05

# =============================================================================
# 1.10 QUERY PACKAGING & CACHING
# =============================================================================
# Packaging final de toutes les représentations et caching.
#
# OUTPUT :
# - Original query
# - Preprocessed query
# - Expanded queries (variantes)
# - Dense embeddings
# - Sparse embeddings
# - ColBERT embeddings
# - Extracted metadata
# - Entities
# - Quality scores
# =============================================================================
query_packaging:
  enabled: true

  # ---------------------------------------------------------------------------
  # STRUCTURE DU PACKAGE
  # ---------------------------------------------------------------------------
  package_structure:
    include:
      - "original_query"
      - "preprocessed_query"
      - "query_type"
      - "query_intent"
      - "query_language"
      - "complexity_score"
      - "expanded_queries"
      - "dense_embeddings"
      - "sparse_embeddings"
      - "colbert_embeddings"
      - "named_entities"
      - "temporal_filters"
      - "geographic_filters"
      - "domain_filters"
      - "quality_scores"

    # Format : "dict", "dataclass", "json"
    format: "dict"

  # ---------------------------------------------------------------------------
  # CACHING AVANCÉ
  # ---------------------------------------------------------------------------
  caching:
    enabled: true

    # Backend : "memory", "redis", "memcached"
    backend: "memory"

    # Configuration memory cache
    memory:
      max_size: 10000
      ttl_seconds: 3600
      eviction_policy: "lru"  # Least Recently Used

    # Configuration Redis (si backend="redis")
    redis:
      host: "localhost"
      port: 6379
      db: 0
      password: "${REDIS_PASSWORD}"

    # Clé de cache
    cache_key_components:
      - "query_text"
      - "language"
      - "enabled_techniques"

  # ---------------------------------------------------------------------------
  # MÉTRIQUES & LOGGING
  # ---------------------------------------------------------------------------
  metrics:
    enabled: true

    # Métriques à tracker
    track:
      - "total_latency_ms"
      - "preprocessing_latency_ms"
      - "expansion_latency_ms"
      - "embedding_latency_ms"
      - "num_variants_generated"
      - "num_variants_filtered"
      - "cache_hit"
      - "complexity_score"
      - "quality_score"

    # Export metrics
    export_to:
      - "prometheus"  # Prometheus metrics
      - "log"         # Log file

# =============================================================================
# PERFORMANCE & OPTIMISATION
# =============================================================================
performance:
  # ---------------------------------------------------------------------------
  # PARALLÉLISATION
  # ---------------------------------------------------------------------------
  parallelization:
    enabled: true

    # Exécuter sous-étapes en parallèle quand possible
    parallel_steps:
      - "ner"
      - "spell_correction"
      - "metadata_extraction"

    # Nombre de workers
    num_workers: 4

  # ---------------------------------------------------------------------------
  # EARLY STOPPING
  # ---------------------------------------------------------------------------
  early_stopping:
    enabled: true

    # Arrêter expansion si suffisamment de variantes de qualité
    criteria:
      min_quality_variants: 3
      min_quality_score: 0.8

  # ---------------------------------------------------------------------------
  # BUDGET LATENCE
  # ---------------------------------------------------------------------------
  latency_budget:
    # Budget total (ms) pour Phase 01
    total_budget_ms: 200

    # Allocation par sous-étape (ms)
    allocation:
      understanding: 10
      preprocessing: 20
      ner: 15
      decomposition: 25
      metadata: 10
      expansion: 80
      embedding: 30
      validation: 10

    # Action si budget dépassé
    # Options : "warn", "abort", "degrade" (désactiver features coûteuses)
    on_exceed: "degrade"

# =============================================================================
# EXAMPLES & USE CASES
# =============================================================================
# Exemples de traitement selon différents types de queries.
#
# EXEMPLE 1 : Query factuelle simple
# Input  : "Quelle est la capitale de la France ?"
# Type   : factual, simple
# Output : 2 variantes (rewrite, original)
# Latency: ~50ms
#
# EXEMPLE 2 : Query analytique complexe
# Input  : "Pourquoi et comment les LLM ont révolutionné le NLP depuis 2020 ?"
# Type   : analytical, complex
# Output : 7 variantes (step_back, hyde, multi_query, decomposition)
# Latency: ~180ms
#
# EXEMPLE 3 : Query avec faute d'orthographe
# Input  : "Coment fonctionne un moteur elekrique ?"
# Preprocessed: "Comment fonctionne un moteur électrique ?"
# Type   : factual, medium
# Output : 4 variantes
# Latency: ~80ms
#
# EXEMPLE 4 : Query multipart avec filtres
# Input  : "Liste des innovations IA en santé depuis 2022 en France"
# Decomposition: ["innovations IA en santé", "depuis 2022", "en France"]
# Metadata: {temporal: "2022-present", geographic: "France", domain: "healthcare"}
# Output : 5 variantes + filtres
# Latency: ~150ms
# =============================================================================
